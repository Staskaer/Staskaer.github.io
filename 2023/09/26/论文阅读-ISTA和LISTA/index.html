<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/imgs/theme_pic/staskaer.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/imgs/theme_pic/staskaer.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/imgs/theme_pic/staskaer.png">
  <link rel="mask-icon" href="/imgs/theme_pic/staskaer.png" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":true,"style":"mac"},"back2top":{"enable":true,"sidebar":false,"scrollpercent":true},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":"valine","storage":true,"lazyload":false,"nav":null,"activeClass":"valine"},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="学习一下LISTA的思想">
<meta property="og:type" content="article">
<meta property="og:title" content="论文阅读-ISTA和LISTA">
<meta property="og:url" content="http://example.com/2023/09/26/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-ISTA%E5%92%8CLISTA/index.html">
<meta property="og:site_name" content="Staskaer">
<meta property="og:description" content="学习一下LISTA的思想">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://example.com/2023/09/26/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-ISTA%E5%92%8CLISTA/pic1.png">
<meta property="og:image" content="http://example.com/2023/09/26/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-ISTA%E5%92%8CLISTA/pic2.png">
<meta property="og:image" content="http://example.com/2023/09/26/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-ISTA%E5%92%8CLISTA/pic3.png">
<meta property="og:image" content="http://example.com/2023/09/26/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-ISTA%E5%92%8CLISTA/pic4.png">
<meta property="og:image" content="http://example.com/2023/09/26/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-ISTA%E5%92%8CLISTA/pic5.png">
<meta property="og:image" content="http://example.com/2023/09/26/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-ISTA%E5%92%8CLISTA/pic6.png">
<meta property="og:image" content="http://example.com/2023/09/26/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-ISTA%E5%92%8CLISTA/pic7.png">
<meta property="og:image" content="http://example.com/2023/09/26/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-ISTA%E5%92%8CLISTA/pic8.png">
<meta property="article:published_time" content="2023-09-26T03:07:48.000Z">
<meta property="article:modified_time" content="2025-06-17T15:50:22.397Z">
<meta property="article:author" content="Staskaer">
<meta property="article:tag" content="SLAM">
<meta property="article:tag" content="论文阅读">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/2023/09/26/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-ISTA%E5%92%8CLISTA/pic1.png">

<link rel="canonical" href="http://example.com/2023/09/26/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-ISTA%E5%92%8CLISTA/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  <title>论文阅读-ISTA和LISTA | Staskaer</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<style>mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

.MathJax path {
  stroke-width: 3;
}

mjx-container[display="true"] {
  overflow: auto hidden;
}

mjx-container[display="true"] + br {
  display: none;
}
</style></head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Staskaer</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">Hi, this is Staskaer</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
        <li class="menu-item menu-item-links">

    <a href="/links/" rel="section"><i class="fa fa-link fa-fw"></i>links</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/09/26/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-ISTA%E5%92%8CLISTA/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/imgs/theme_pic/head_img.png">
      <meta itemprop="name" content="Staskaer">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Staskaer">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          论文阅读-ISTA和LISTA
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2023-09-26 11:07:48" itemprop="dateCreated datePublished" datetime="2023-09-26T11:07:48+08:00">2023-09-26</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2025-06-17 23:50:22" itemprop="dateModified" datetime="2025-06-17T23:50:22+08:00">2025-06-17</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/SLAM%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">SLAM学习</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2023/09/26/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-ISTA%E5%92%8CLISTA/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2023/09/26/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-ISTA%E5%92%8CLISTA/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>学习一下LISTA的思想</p>
<span id="more"></span>
<h2 id="learning-fast-approximations-of-sparse-coding">Learning Fast Approximations of Sparse Coding</h2>
<p>主要阅读<a target="_blank" rel="noopener" href="http://yann.lecun.com/exdb/publis/pdf/gregor-icml-10.pdf">这篇论文</a>，代码参考<a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_38290475/article/details/104684232">这篇文章</a></p>
<p>学习这篇文章的目的是为掌握一下在普通的算法中加入网络模型后的训练方法，而不是局限于ISTA算法本身的细节。</p>
<h3 id="ista">ISTA</h3>
<p>ISTA目的是求解这样一个问题，对于一个n维向量<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: 0;" xmlns="http://www.w3.org/2000/svg" width="2.143ex" height="1.552ex" role="img" focusable="false" viewBox="0 -686 947 686"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D47F" d="M931 686Q953 686 953 670Q953 650 944 632Q936 624 924 624H914Q823 624 803 611Q800 609 696 503T591 396Q591 394 667 229L743 62H787H814Q846 62 846 44Q843 7 829 2Q825 0 817 0Q813 0 775 1T664 2Q590 2 551 1T508 0H507Q484 0 484 18Q484 19 488 37Q492 56 497 58T534 62L566 63Q567 64 520 169T471 274Q469 274 369 172T268 67L315 62Q320 62 328 62L335 61Q347 58 347 44Q344 10 331 2L326 0L287 1Q263 2 177 2Q95 2 78 1L53 0Q38 6 38 17Q38 40 50 57Q56 62 78 62Q169 62 188 75Q194 77 435 324L444 334L439 347Q437 351 373 492L313 624H268H246Q220 624 212 632Q210 636 210 642Q210 655 215 669T227 684Q230 686 247 686Q295 684 398 684Q438 684 472 684T527 685T551 686Q567 686 572 671Q572 667 568 651Q563 631 558 628T523 624T492 623H488L526 540Q563 457 564 457Q564 456 574 466T604 496T645 537L724 619Q716 622 677 624H673Q645 624 645 640Q645 660 654 678Q659 683 666 686L704 685Q728 684 813 684Q847 684 873 684T913 685T931 686Z"></path></g></g></g></svg></mjx-container></span>，希望找到一个最佳的稀疏编码<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: 0;" xmlns="http://www.w3.org/2000/svg" width="1.821ex" height="1.552ex" role="img" focusable="false" viewBox="0 -686 805 686"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D481" d="M223 430Q192 430 192 448Q192 450 225 561T261 677Q265 683 270 684Q273 686 534 686Q796 686 797 685Q805 682 805 673Q805 668 804 661T800 648T798 641Q796 637 531 352L266 67L329 66H364Q412 66 446 70T523 96T596 157Q617 186 630 220T649 273T663 297Q667 299 684 299H688Q715 299 715 281Q715 278 673 145T628 8Q626 4 617 0H348Q289 0 221 0T139 -1Q112 -1 99 -1T78 1T69 5T68 12Q68 16 71 31T77 49L84 57Q91 65 104 79T133 110T170 151T213 196L610 624H540Q533 624 514 624T488 624T467 623T443 620T422 616T398 609T373 600Q292 560 255 449Q251 436 246 433T223 430Z"></path></g></g></g></svg></mjx-container></span>，且编码维度为m小于n，使得<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: 0;" xmlns="http://www.w3.org/2000/svg" width="2.143ex" height="1.552ex" role="img" focusable="false" viewBox="0 -686 947 686"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D47F" d="M931 686Q953 686 953 670Q953 650 944 632Q936 624 924 624H914Q823 624 803 611Q800 609 696 503T591 396Q591 394 667 229L743 62H787H814Q846 62 846 44Q843 7 829 2Q825 0 817 0Q813 0 775 1T664 2Q590 2 551 1T508 0H507Q484 0 484 18Q484 19 488 37Q492 56 497 58T534 62L566 63Q567 64 520 169T471 274Q469 274 369 172T268 67L315 62Q320 62 328 62L335 61Q347 58 347 44Q344 10 331 2L326 0L287 1Q263 2 177 2Q95 2 78 1L53 0Q38 6 38 17Q38 40 50 57Q56 62 78 62Q169 62 188 75Q194 77 435 324L444 334L439 347Q437 351 373 492L313 624H268H246Q220 624 212 632Q210 636 210 642Q210 655 215 669T227 684Q230 686 247 686Q295 684 398 684Q438 684 472 684T527 685T551 686Q567 686 572 671Q572 667 568 651Q563 631 558 628T523 624T492 623H488L526 540Q563 457 564 457Q564 456 574 466T604 496T645 537L724 619Q716 622 677 624H673Q645 624 645 640Q645 660 654 678Q659 683 666 686L704 685Q728 684 813 684Q847 684 873 684T913 685T931 686Z"></path></g></g></g></svg></mjx-container></span>可以由<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.352ex;" xmlns="http://www.w3.org/2000/svg" width="3.637ex" height="1.904ex" role="img" focusable="false" viewBox="0 -686 1607.3 841.7"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D47E" d="M111 624Q109 624 102 624T91 623Q61 623 61 640Q61 660 70 678Q78 686 98 686Q140 684 239 684Q277 684 309 684T360 685T383 686H385Q407 686 407 668Q404 634 391 626Q387 624 348 624Q307 624 307 622Q307 618 332 409Q359 198 359 195L570 532L564 576L558 622V624H522H504Q472 624 472 641Q475 678 488 684L493 686L529 685Q551 684 645 684Q716 684 753 685T795 686Q818 686 818 669Q815 632 802 626Q798 624 759 624Q718 624 718 622Q718 615 743 410Q770 199 770 196Q770 195 806 253T903 406Q1035 618 1035 619Q1025 624 968 624Q943 624 943 641Q943 648 946 659Q950 675 952 679T963 686L998 685Q1020 684 1093 684Q1113 684 1139 685T1173 686Q1207 686 1207 669Q1207 664 1204 652Q1199 631 1194 628T1164 624Q1113 622 1101 615Q1098 612 905 305Q715 -1 709 -7Q699 -17 673 -17Q645 -17 639 -8L581 441Q581 444 442 221Q331 44 314 18T288 -14Q279 -17 263 -17H254Q229 -17 227 -5Q225 2 186 311L147 620V624H111Z"></path></g><g data-mml-node="mi" transform="translate(1126,-150) scale(0.707)"><path data-c="1D485" d="M222 -8Q140 -8 89 34T38 158Q38 220 68 285T151 391Q230 452 329 452Q382 452 416 428L422 424Q423 424 447 523L472 622H468Q467 622 463 622T453 623T441 624T430 624T420 624T415 625Q403 628 403 642Q403 647 407 661T413 679Q417 684 428 685T504 690Q577 694 591 694Q608 694 612 679L467 91Q466 87 466 72Q466 43 483 43Q518 43 541 134Q546 155 550 158T571 162H576H587Q607 162 607 148Q606 142 604 132T590 94T566 47T528 9T474 -8Q396 -8 358 40Q295 -8 222 -8ZM404 351Q383 401 324 401Q300 401 270 385T221 330Q206 296 186 220Q166 136 166 106Q166 72 184 58T228 43Q256 43 284 57T328 84T343 103Q343 106 374 228L404 351Z"></path></g></g></g></g></svg></mjx-container></span>和<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: 0;" xmlns="http://www.w3.org/2000/svg" width="1.821ex" height="1.552ex" role="img" focusable="false" viewBox="0 -686 805 686"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D481" d="M223 430Q192 430 192 448Q192 450 225 561T261 677Q265 683 270 684Q273 686 534 686Q796 686 797 685Q805 682 805 673Q805 668 804 661T800 648T798 641Q796 637 531 352L266 67L329 66H364Q412 66 446 70T523 96T596 157Q617 186 630 220T649 273T663 297Q667 299 684 299H688Q715 299 715 281Q715 278 673 145T628 8Q626 4 617 0H348Q289 0 221 0T139 -1Q112 -1 99 -1T78 1T69 5T68 12Q68 16 71 31T77 49L84 57Q91 65 104 79T133 110T170 151T213 196L610 624H540Q533 624 514 624T488 624T467 623T443 620T422 616T398 609T373 600Q292 560 255 449Q251 436 246 433T223 430Z"></path></g></g></g></svg></mjx-container></span>线性表示，即</p>
<p><span class="math display"><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -0.352ex;" xmlns="http://www.w3.org/2000/svg" width="10.617ex" height="1.904ex" role="img" focusable="false" viewBox="0 -686 4692.9 841.7"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D47F" d="M931 686Q953 686 953 670Q953 650 944 632Q936 624 924 624H914Q823 624 803 611Q800 609 696 503T591 396Q591 394 667 229L743 62H787H814Q846 62 846 44Q843 7 829 2Q825 0 817 0Q813 0 775 1T664 2Q590 2 551 1T508 0H507Q484 0 484 18Q484 19 488 37Q492 56 497 58T534 62L566 63Q567 64 520 169T471 274Q469 274 369 172T268 67L315 62Q320 62 328 62L335 61Q347 58 347 44Q344 10 331 2L326 0L287 1Q263 2 177 2Q95 2 78 1L53 0Q38 6 38 17Q38 40 50 57Q56 62 78 62Q169 62 188 75Q194 77 435 324L444 334L439 347Q437 351 373 492L313 624H268H246Q220 624 212 632Q210 636 210 642Q210 655 215 669T227 684Q230 686 247 686Q295 684 398 684Q438 684 472 684T527 685T551 686Q567 686 572 671Q572 667 568 651Q563 631 558 628T523 624T492 623H488L526 540Q563 457 564 457Q564 456 574 466T604 496T645 537L724 619Q716 622 677 624H673Q645 624 645 640Q645 660 654 678Q659 683 666 686L704 685Q728 684 813 684Q847 684 873 684T913 685T931 686Z"></path></g><g data-mml-node="mo" transform="translate(1224.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="msub" transform="translate(2280.6,0)"><g data-mml-node="mi"><path data-c="1D47E" d="M111 624Q109 624 102 624T91 623Q61 623 61 640Q61 660 70 678Q78 686 98 686Q140 684 239 684Q277 684 309 684T360 685T383 686H385Q407 686 407 668Q404 634 391 626Q387 624 348 624Q307 624 307 622Q307 618 332 409Q359 198 359 195L570 532L564 576L558 622V624H522H504Q472 624 472 641Q475 678 488 684L493 686L529 685Q551 684 645 684Q716 684 753 685T795 686Q818 686 818 669Q815 632 802 626Q798 624 759 624Q718 624 718 622Q718 615 743 410Q770 199 770 196Q770 195 806 253T903 406Q1035 618 1035 619Q1025 624 968 624Q943 624 943 641Q943 648 946 659Q950 675 952 679T963 686L998 685Q1020 684 1093 684Q1113 684 1139 685T1173 686Q1207 686 1207 669Q1207 664 1204 652Q1199 631 1194 628T1164 624Q1113 622 1101 615Q1098 612 905 305Q715 -1 709 -7Q699 -17 673 -17Q645 -17 639 -8L581 441Q581 444 442 221Q331 44 314 18T288 -14Q279 -17 263 -17H254Q229 -17 227 -5Q225 2 186 311L147 620V624H111Z"></path></g><g data-mml-node="mi" transform="translate(1126,-150) scale(0.707)"><path data-c="1D485" d="M222 -8Q140 -8 89 34T38 158Q38 220 68 285T151 391Q230 452 329 452Q382 452 416 428L422 424Q423 424 447 523L472 622H468Q467 622 463 622T453 623T441 624T430 624T420 624T415 625Q403 628 403 642Q403 647 407 661T413 679Q417 684 428 685T504 690Q577 694 591 694Q608 694 612 679L467 91Q466 87 466 72Q466 43 483 43Q518 43 541 134Q546 155 550 158T571 162H576H587Q607 162 607 148Q606 142 604 132T590 94T566 47T528 9T474 -8Q396 -8 358 40Q295 -8 222 -8ZM404 351Q383 401 324 401Q300 401 270 385T221 330Q206 296 186 220Q166 136 166 106Q166 72 184 58T228 43Q256 43 284 57T328 84T343 103Q343 106 374 228L404 351Z"></path></g></g><g data-mml-node="mi" transform="translate(3887.9,0)"><path data-c="1D481" d="M223 430Q192 430 192 448Q192 450 225 561T261 677Q265 683 270 684Q273 686 534 686Q796 686 797 685Q805 682 805 673Q805 668 804 661T800 648T798 641Q796 637 531 352L266 67L329 66H364Q412 66 446 70T523 96T596 157Q617 186 630 220T649 273T663 297Q667 299 684 299H688Q715 299 715 281Q715 278 673 145T628 8Q626 4 617 0H348Q289 0 221 0T139 -1Q112 -1 99 -1T78 1T69 5T68 12Q68 16 71 31T77 49L84 57Q91 65 104 79T133 110T170 151T213 196L610 624H540Q533 624 514 624T488 624T467 623T443 620T422 616T398 609T373 600Q292 560 255 449Q251 436 246 433T223 430Z"></path></g></g></g></svg></mjx-container></span></p>
<p>由此，可以构建带有L1正则化项的损失函数（L1正则化项能让输出趋向于稀疏），而ISTA算法本身也可以求解lasso回归问题，可以有效避免求解大矩阵的逆</p>
<p><span class="math display"><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -1.552ex;" xmlns="http://www.w3.org/2000/svg" width="34.445ex" height="4.588ex" role="img" focusable="false" viewBox="0 -1342 15224.9 2028"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="4C" d="M62 -22T47 -22T32 -11Q32 -1 56 24T83 55Q113 96 138 172T180 320T234 473T323 609Q364 649 419 677T531 705Q559 705 578 696T604 671T615 645T618 623V611Q618 582 615 571T598 548Q581 531 558 520T518 509Q503 509 503 520Q503 523 505 536T507 560Q507 590 494 610T452 630Q423 630 410 617Q367 578 333 492T271 301T233 170Q211 123 204 112L198 103L224 102Q281 102 369 79T509 52H523Q535 64 544 87T579 128Q616 152 641 152Q656 152 656 142Q656 101 588 40T433 -22Q381 -22 289 1T156 28L141 29L131 20Q111 0 87 -11Z"></path></g></g><g data-mml-node="mo" transform="translate(690,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(1079,0)"><path data-c="1D481" d="M223 430Q192 430 192 448Q192 450 225 561T261 677Q265 683 270 684Q273 686 534 686Q796 686 797 685Q805 682 805 673Q805 668 804 661T800 648T798 641Q796 637 531 352L266 67L329 66H364Q412 66 446 70T523 96T596 157Q617 186 630 220T649 273T663 297Q667 299 684 299H688Q715 299 715 281Q715 278 673 145T628 8Q626 4 617 0H348Q289 0 221 0T139 -1Q112 -1 99 -1T78 1T69 5T68 12Q68 16 71 31T77 49L84 57Q91 65 104 79T133 110T170 151T213 196L610 624H540Q533 624 514 624T488 624T467 623T443 620T422 616T398 609T373 600Q292 560 255 449Q251 436 246 433T223 430Z"></path></g><g data-mml-node="mo" transform="translate(1884,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(2550.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mfrac" transform="translate(3606.6,0)"><g data-mml-node="mn" transform="translate(220,676)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g><g data-mml-node="mn" transform="translate(220,-686)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><rect width="700" height="60" x="120" y="220"></rect></g><g data-mml-node="mo" transform="translate(4546.6,0)"><path data-c="2225" d="M133 736Q138 750 153 750Q164 750 170 739Q172 735 172 250T170 -239Q164 -250 152 -250Q144 -250 138 -244L137 -243Q133 -241 133 -179T132 250Q132 731 133 736ZM329 739Q334 750 346 750Q353 750 361 744L362 743Q366 741 366 679T367 250T367 -178T362 -243L361 -244Q355 -250 347 -250Q335 -250 329 -239Q327 -235 327 250T329 739Z"></path></g><g data-mml-node="mo" transform="translate(5046.6,0) translate(0 -0.5)"><path data-c="7C" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z"></path></g><g data-mml-node="mi" transform="translate(5324.6,0)"><path data-c="1D47F" d="M931 686Q953 686 953 670Q953 650 944 632Q936 624 924 624H914Q823 624 803 611Q800 609 696 503T591 396Q591 394 667 229L743 62H787H814Q846 62 846 44Q843 7 829 2Q825 0 817 0Q813 0 775 1T664 2Q590 2 551 1T508 0H507Q484 0 484 18Q484 19 488 37Q492 56 497 58T534 62L566 63Q567 64 520 169T471 274Q469 274 369 172T268 67L315 62Q320 62 328 62L335 61Q347 58 347 44Q344 10 331 2L326 0L287 1Q263 2 177 2Q95 2 78 1L53 0Q38 6 38 17Q38 40 50 57Q56 62 78 62Q169 62 188 75Q194 77 435 324L444 334L439 347Q437 351 373 492L313 624H268H246Q220 624 212 632Q210 636 210 642Q210 655 215 669T227 684Q230 686 247 686Q295 684 398 684Q438 684 472 684T527 685T551 686Q567 686 572 671Q572 667 568 651Q563 631 558 628T523 624T492 623H488L526 540Q563 457 564 457Q564 456 574 466T604 496T645 537L724 619Q716 622 677 624H673Q645 624 645 640Q645 660 654 678Q659 683 666 686L704 685Q728 684 813 684Q847 684 873 684T913 685T931 686Z"></path></g><g data-mml-node="mo" transform="translate(6493.8,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="msub" transform="translate(7494,0)"><g data-mml-node="mi"><path data-c="1D47E" d="M111 624Q109 624 102 624T91 623Q61 623 61 640Q61 660 70 678Q78 686 98 686Q140 684 239 684Q277 684 309 684T360 685T383 686H385Q407 686 407 668Q404 634 391 626Q387 624 348 624Q307 624 307 622Q307 618 332 409Q359 198 359 195L570 532L564 576L558 622V624H522H504Q472 624 472 641Q475 678 488 684L493 686L529 685Q551 684 645 684Q716 684 753 685T795 686Q818 686 818 669Q815 632 802 626Q798 624 759 624Q718 624 718 622Q718 615 743 410Q770 199 770 196Q770 195 806 253T903 406Q1035 618 1035 619Q1025 624 968 624Q943 624 943 641Q943 648 946 659Q950 675 952 679T963 686L998 685Q1020 684 1093 684Q1113 684 1139 685T1173 686Q1207 686 1207 669Q1207 664 1204 652Q1199 631 1194 628T1164 624Q1113 622 1101 615Q1098 612 905 305Q715 -1 709 -7Q699 -17 673 -17Q645 -17 639 -8L581 441Q581 444 442 221Q331 44 314 18T288 -14Q279 -17 263 -17H254Q229 -17 227 -5Q225 2 186 311L147 620V624H111Z"></path></g><g data-mml-node="mi" transform="translate(1126,-150) scale(0.707)"><path data-c="1D485" d="M222 -8Q140 -8 89 34T38 158Q38 220 68 285T151 391Q230 452 329 452Q382 452 416 428L422 424Q423 424 447 523L472 622H468Q467 622 463 622T453 623T441 624T430 624T420 624T415 625Q403 628 403 642Q403 647 407 661T413 679Q417 684 428 685T504 690Q577 694 591 694Q608 694 612 679L467 91Q466 87 466 72Q466 43 483 43Q518 43 541 134Q546 155 550 158T571 162H576H587Q607 162 607 148Q606 142 604 132T590 94T566 47T528 9T474 -8Q396 -8 358 40Q295 -8 222 -8ZM404 351Q383 401 324 401Q300 401 270 385T221 330Q206 296 186 220Q166 136 166 106Q166 72 184 58T228 43Q256 43 284 57T328 84T343 103Q343 106 374 228L404 351Z"></path></g></g><g data-mml-node="mi" transform="translate(9101.3,0)"><path data-c="1D481" d="M223 430Q192 430 192 448Q192 450 225 561T261 677Q265 683 270 684Q273 686 534 686Q796 686 797 685Q805 682 805 673Q805 668 804 661T800 648T798 641Q796 637 531 352L266 67L329 66H364Q412 66 446 70T523 96T596 157Q617 186 630 220T649 273T663 297Q667 299 684 299H688Q715 299 715 281Q715 278 673 145T628 8Q626 4 617 0H348Q289 0 221 0T139 -1Q112 -1 99 -1T78 1T69 5T68 12Q68 16 71 31T77 49L84 57Q91 65 104 79T133 110T170 151T213 196L610 624H540Q533 624 514 624T488 624T467 623T443 620T422 616T398 609T373 600Q292 560 255 449Q251 436 246 433T223 430Z"></path></g><g data-mml-node="mo" transform="translate(9906.3,0)"><path data-c="2225" d="M133 736Q138 750 153 750Q164 750 170 739Q172 735 172 250T170 -239Q164 -250 152 -250Q144 -250 138 -244L137 -243Q133 -241 133 -179T132 250Q132 731 133 736ZM329 739Q334 750 346 750Q353 750 361 744L362 743Q366 741 366 679T367 250T367 -178T362 -243L361 -244Q355 -250 347 -250Q335 -250 329 -239Q327 -235 327 250T329 739Z"></path></g><g data-mml-node="msubsup" transform="translate(10406.3,0)"><g data-mml-node="mo" transform="translate(0 -0.5)"><path data-c="7C" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z"></path></g><g data-mml-node="TeXAtom" transform="translate(311,413) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g><g data-mml-node="TeXAtom" transform="translate(311,-247) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g></g><g data-mml-node="mo" transform="translate(11343.1,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="mi" transform="translate(12343.3,0)"><path data-c="1D6FC" d="M34 156Q34 270 120 356T309 442Q379 442 421 402T478 304Q484 275 485 237V208Q534 282 560 374Q564 388 566 390T582 393Q603 393 603 385Q603 376 594 346T558 261T497 161L486 147L487 123Q489 67 495 47T514 26Q528 28 540 37T557 60Q559 67 562 68T577 70Q597 70 597 62Q597 56 591 43Q579 19 556 5T512 -10H505Q438 -10 414 62L411 69L400 61Q390 53 370 41T325 18T267 -2T203 -11Q124 -11 79 39T34 156ZM208 26Q257 26 306 47T379 90L403 112Q401 255 396 290Q382 405 304 405Q235 405 183 332Q156 292 139 224T121 120Q121 71 146 49T208 26Z"></path></g><g data-mml-node="mo" transform="translate(12983.3,0)"><path data-c="2225" d="M133 736Q138 750 153 750Q164 750 170 739Q172 735 172 250T170 -239Q164 -250 152 -250Q144 -250 138 -244L137 -243Q133 -241 133 -179T132 250Q132 731 133 736ZM329 739Q334 750 346 750Q353 750 361 744L362 743Q366 741 366 679T367 250T367 -178T362 -243L361 -244Q355 -250 347 -250Q335 -250 329 -239Q327 -235 327 250T329 739Z"></path></g><g data-mml-node="mi" transform="translate(13483.3,0)"><path data-c="1D481" d="M223 430Q192 430 192 448Q192 450 225 561T261 677Q265 683 270 684Q273 686 534 686Q796 686 797 685Q805 682 805 673Q805 668 804 661T800 648T798 641Q796 637 531 352L266 67L329 66H364Q412 66 446 70T523 96T596 157Q617 186 630 220T649 273T663 297Q667 299 684 299H688Q715 299 715 281Q715 278 673 145T628 8Q626 4 617 0H348Q289 0 221 0T139 -1Q112 -1 99 -1T78 1T69 5T68 12Q68 16 71 31T77 49L84 57Q91 65 104 79T133 110T170 151T213 196L610 624H540Q533 624 514 624T488 624T467 623T443 620T422 616T398 609T373 600Q292 560 255 449Q251 436 246 433T223 430Z"></path></g><g data-mml-node="msub" transform="translate(14288.3,0)"><g data-mml-node="mo"><path data-c="2225" d="M133 736Q138 750 153 750Q164 750 170 739Q172 735 172 250T170 -239Q164 -250 152 -250Q144 -250 138 -244L137 -243Q133 -241 133 -179T132 250Q132 731 133 736ZM329 739Q334 750 346 750Q353 750 361 744L362 743Q366 741 366 679T367 250T367 -178T362 -243L361 -244Q355 -250 347 -250Q335 -250 329 -239Q327 -235 327 250T329 739Z"></path></g><g data-mml-node="TeXAtom" transform="translate(533,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g></g></g></svg></mjx-container></span></p>
<p>所以目的就是最小化此损失函数即可，而ISTA的思想就是通过迭代的方式来求解，每次迭代的更新公式为，其中L是一个常数，要比<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.709ex;" xmlns="http://www.w3.org/2000/svg" width="7.916ex" height="2.61ex" role="img" focusable="false" viewBox="0 -840.3 3498.9 1153.7"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msubsup"><g data-mml-node="mi"><path data-c="1D47E" d="M111 624Q109 624 102 624T91 623Q61 623 61 640Q61 660 70 678Q78 686 98 686Q140 684 239 684Q277 684 309 684T360 685T383 686H385Q407 686 407 668Q404 634 391 626Q387 624 348 624Q307 624 307 622Q307 618 332 409Q359 198 359 195L570 532L564 576L558 622V624H522H504Q472 624 472 641Q475 678 488 684L493 686L529 685Q551 684 645 684Q716 684 753 685T795 686Q818 686 818 669Q815 632 802 626Q798 624 759 624Q718 624 718 622Q718 615 743 410Q770 199 770 196Q770 195 806 253T903 406Q1035 618 1035 619Q1025 624 968 624Q943 624 943 641Q943 648 946 659Q950 675 952 679T963 686L998 685Q1020 684 1093 684Q1113 684 1139 685T1173 686Q1207 686 1207 669Q1207 664 1204 652Q1199 631 1194 628T1164 624Q1113 622 1101 615Q1098 612 905 305Q715 -1 709 -7Q699 -17 673 -17Q645 -17 639 -8L581 441Q581 444 442 221Q331 44 314 18T288 -14Q279 -17 263 -17H254Q229 -17 227 -5Q225 2 186 311L147 620V624H111Z"></path></g><g data-mml-node="mi" transform="translate(1295.7,363) scale(0.707)"><path data-c="1D47B" d="M498 62Q511 58 511 43Q511 10 494 1L490 0Q487 0 482 0T424 1T271 2Q201 2 157 2T94 1T72 0H70Q46 0 46 17Q49 54 62 60L66 62H137Q208 62 209 63L218 98Q227 134 244 203T278 339L347 613H300Q262 612 246 611T198 599T146 564Q128 545 114 512T91 454T79 425Q73 419 52 419Q22 419 22 434Q22 440 41 498T80 611L100 666Q105 673 111 675H434Q758 675 762 673Q772 668 772 657Q772 655 756 549T738 434Q735 419 711 419H707Q690 419 686 421Q677 425 677 434Q676 436 678 449T683 485T686 529Q686 553 679 569T662 594T631 607T593 612T544 613H502L433 340Q418 279 400 207T374 100L365 65L364 62H498Z"></path></g><g data-mml-node="mi" transform="translate(1126,-307.7) scale(0.707)"><path data-c="1D485" d="M222 -8Q140 -8 89 34T38 158Q38 220 68 285T151 391Q230 452 329 452Q382 452 416 428L422 424Q423 424 447 523L472 622H468Q467 622 463 622T453 623T441 624T430 624T420 624T415 625Q403 628 403 642Q403 647 407 661T413 679Q417 684 428 685T504 690Q577 694 591 694Q608 694 612 679L467 91Q466 87 466 72Q466 43 483 43Q518 43 541 134Q546 155 550 158T571 162H576H587Q607 162 607 148Q606 142 604 132T590 94T566 47T528 9T474 -8Q396 -8 358 40Q295 -8 222 -8ZM404 351Q383 401 324 401Q300 401 270 385T221 330Q206 296 186 220Q166 136 166 106Q166 72 184 58T228 43Q256 43 284 57T328 84T343 103Q343 106 374 228L404 351Z"></path></g></g><g data-mml-node="msub" transform="translate(1891.6,0)"><g data-mml-node="mi"><path data-c="1D47E" d="M111 624Q109 624 102 624T91 623Q61 623 61 640Q61 660 70 678Q78 686 98 686Q140 684 239 684Q277 684 309 684T360 685T383 686H385Q407 686 407 668Q404 634 391 626Q387 624 348 624Q307 624 307 622Q307 618 332 409Q359 198 359 195L570 532L564 576L558 622V624H522H504Q472 624 472 641Q475 678 488 684L493 686L529 685Q551 684 645 684Q716 684 753 685T795 686Q818 686 818 669Q815 632 802 626Q798 624 759 624Q718 624 718 622Q718 615 743 410Q770 199 770 196Q770 195 806 253T903 406Q1035 618 1035 619Q1025 624 968 624Q943 624 943 641Q943 648 946 659Q950 675 952 679T963 686L998 685Q1020 684 1093 684Q1113 684 1139 685T1173 686Q1207 686 1207 669Q1207 664 1204 652Q1199 631 1194 628T1164 624Q1113 622 1101 615Q1098 612 905 305Q715 -1 709 -7Q699 -17 673 -17Q645 -17 639 -8L581 441Q581 444 442 221Q331 44 314 18T288 -14Q279 -17 263 -17H254Q229 -17 227 -5Q225 2 186 311L147 620V624H111Z"></path></g><g data-mml-node="mi" transform="translate(1126,-150) scale(0.707)"><path data-c="1D485" d="M222 -8Q140 -8 89 34T38 158Q38 220 68 285T151 391Q230 452 329 452Q382 452 416 428L422 424Q423 424 447 523L472 622H468Q467 622 463 622T453 623T441 624T430 624T420 624T415 625Q403 628 403 642Q403 647 407 661T413 679Q417 684 428 685T504 690Q577 694 591 694Q608 694 612 679L467 91Q466 87 466 72Q466 43 483 43Q518 43 541 134Q546 155 550 158T571 162H576H587Q607 162 607 148Q606 142 604 132T590 94T566 47T528 9T474 -8Q396 -8 358 40Q295 -8 222 -8ZM404 351Q383 401 324 401Q300 401 270 385T221 330Q206 296 186 220Q166 136 166 106Q166 72 184 58T228 43Q256 43 284 57T328 84T343 103Q343 106 374 228L404 351Z"></path></g></g></g></g></svg></mjx-container></span>的最大特征值大</p>
<p><span class="math display"><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -1.552ex;" xmlns="http://www.w3.org/2000/svg" width="33.581ex" height="4.588ex" role="img" focusable="false" viewBox="0 -1342 14842.8 2028"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D481" d="M223 430Q192 430 192 448Q192 450 225 561T261 677Q265 683 270 684Q273 686 534 686Q796 686 797 685Q805 682 805 673Q805 668 804 661T800 648T798 641Q796 637 531 352L266 67L329 66H364Q412 66 446 70T523 96T596 157Q617 186 630 220T649 273T663 297Q667 299 684 299H688Q715 299 715 281Q715 278 673 145T628 8Q626 4 617 0H348Q289 0 221 0T139 -1Q112 -1 99 -1T78 1T69 5T68 12Q68 16 71 31T77 49L84 57Q91 65 104 79T133 110T170 151T213 196L610 624H540Q533 624 514 624T488 624T467 623T443 620T422 616T398 609T373 600Q292 560 255 449Q251 436 246 433T223 430Z"></path></g><g data-mml-node="mo" transform="translate(1082.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="msub" transform="translate(2138.6,0)"><g data-mml-node="mi"><path data-c="210E" d="M137 683Q138 683 209 688T282 694Q294 694 294 685Q294 674 258 534Q220 386 220 383Q220 381 227 388Q288 442 357 442Q411 442 444 415T478 336Q478 285 440 178T402 50Q403 36 407 31T422 26Q450 26 474 56T513 138Q516 149 519 151T535 153Q555 153 555 145Q555 144 551 130Q535 71 500 33Q466 -10 419 -10H414Q367 -10 346 17T325 74Q325 90 361 192T398 345Q398 404 354 404H349Q266 404 205 306L198 293L164 158Q132 28 127 16Q114 -11 83 -11Q69 -11 59 -2T48 16Q48 30 121 320L195 616Q195 629 188 632T149 637H128Q122 643 122 645T124 664Q129 683 137 683Z"></path></g><g data-mml-node="TeXAtom" transform="translate(609,-176.7) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D6FC" d="M34 156Q34 270 120 356T309 442Q379 442 421 402T478 304Q484 275 485 237V208Q534 282 560 374Q564 388 566 390T582 393Q603 393 603 385Q603 376 594 346T558 261T497 161L486 147L487 123Q489 67 495 47T514 26Q528 28 540 37T557 60Q559 67 562 68T577 70Q597 70 597 62Q597 56 591 43Q579 19 556 5T512 -10H505Q438 -10 414 62L411 69L400 61Q390 53 370 41T325 18T267 -2T203 -11Q124 -11 79 39T34 156ZM208 26Q257 26 306 47T379 90L403 112Q401 255 396 290Q382 405 304 405Q235 405 183 332Q156 292 139 224T121 120Q121 71 146 49T208 26Z"></path></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(640,0)"><g data-mml-node="mo"><path data-c="2F" d="M423 750Q432 750 438 744T444 730Q444 725 271 248T92 -240Q85 -250 75 -250Q68 -250 62 -245T56 -231Q56 -221 230 257T407 740Q411 750 423 750Z"></path></g></g><g data-mml-node="mi" transform="translate(1140,0)"><path data-c="1D43F" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 217 683Q271 680 344 680Q485 680 506 683H518Q524 677 524 674T522 656Q517 641 513 637H475Q406 636 394 628Q387 624 380 600T313 336Q297 271 279 198T252 88L243 52Q243 48 252 48T311 46H328Q360 46 379 47T428 54T478 72T522 106T564 161Q580 191 594 228T611 270Q616 273 628 273H641Q647 264 647 262T627 203T583 83T557 9Q555 4 553 3T537 0T494 -1Q483 -1 418 -1T294 0H116Q32 0 32 10Q32 17 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z"></path></g></g></g><g data-mml-node="mo" transform="translate(4085.2,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(4474.2,0)"><path data-c="1D481" d="M223 430Q192 430 192 448Q192 450 225 561T261 677Q265 683 270 684Q273 686 534 686Q796 686 797 685Q805 682 805 673Q805 668 804 661T800 648T798 641Q796 637 531 352L266 67L329 66H364Q412 66 446 70T523 96T596 157Q617 186 630 220T649 273T663 297Q667 299 684 299H688Q715 299 715 281Q715 278 673 145T628 8Q626 4 617 0H348Q289 0 221 0T139 -1Q112 -1 99 -1T78 1T69 5T68 12Q68 16 71 31T77 49L84 57Q91 65 104 79T133 110T170 151T213 196L610 624H540Q533 624 514 624T488 624T467 623T443 620T422 616T398 609T373 600Q292 560 255 449Q251 436 246 433T223 430Z"></path></g><g data-mml-node="mo" transform="translate(5501.4,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mfrac" transform="translate(6501.6,0)"><g data-mml-node="mn" transform="translate(310.5,676)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g><g data-mml-node="mi" transform="translate(220,-686)"><path data-c="1D43F" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 217 683Q271 680 344 680Q485 680 506 683H518Q524 677 524 674T522 656Q517 641 513 637H475Q406 636 394 628Q387 624 380 600T313 336Q297 271 279 198T252 88L243 52Q243 48 252 48T311 46H328Q360 46 379 47T428 54T478 72T522 106T564 161Q580 191 594 228T611 270Q616 273 628 273H641Q647 264 647 262T627 203T583 83T557 9Q555 4 553 3T537 0T494 -1Q483 -1 418 -1T294 0H116Q32 0 32 10Q32 17 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z"></path></g><rect width="881" height="60" x="120" y="220"></rect></g><g data-mml-node="msubsup" transform="translate(7622.6,0)"><g data-mml-node="mi"><path data-c="1D44A" d="M436 683Q450 683 486 682T553 680Q604 680 638 681T677 682Q695 682 695 674Q695 670 692 659Q687 641 683 639T661 637Q636 636 621 632T600 624T597 615Q597 603 613 377T629 138L631 141Q633 144 637 151T649 170T666 200T690 241T720 295T759 362Q863 546 877 572T892 604Q892 619 873 628T831 637Q817 637 817 647Q817 650 819 660Q823 676 825 679T839 682Q842 682 856 682T895 682T949 681Q1015 681 1034 683Q1048 683 1048 672Q1048 666 1045 655T1038 640T1028 637Q1006 637 988 631T958 617T939 600T927 584L923 578L754 282Q586 -14 585 -15Q579 -22 561 -22Q546 -22 542 -17Q539 -14 523 229T506 480L494 462Q472 425 366 239Q222 -13 220 -15T215 -19Q210 -22 197 -22Q178 -22 176 -15Q176 -12 154 304T131 622Q129 631 121 633T82 637H58Q51 644 51 648Q52 671 64 683H76Q118 680 176 680Q301 680 313 683H323Q329 677 329 674T327 656Q322 641 318 637H297Q236 634 232 620Q262 160 266 136L501 550L499 587Q496 629 489 632Q483 636 447 637Q428 637 422 639T416 648Q416 650 418 660Q419 664 420 669T421 676T424 680T428 682T436 683Z"></path></g><g data-mml-node="mi" transform="translate(1136.2,413) scale(0.707)"><path data-c="1D447" d="M40 437Q21 437 21 445Q21 450 37 501T71 602L88 651Q93 669 101 677H569H659Q691 677 697 676T704 667Q704 661 687 553T668 444Q668 437 649 437Q640 437 637 437T631 442L629 445Q629 451 635 490T641 551Q641 586 628 604T573 629Q568 630 515 631Q469 631 457 630T439 622Q438 621 368 343T298 60Q298 48 386 46Q418 46 427 45T436 36Q436 31 433 22Q429 4 424 1L422 0Q419 0 415 0Q410 0 363 1T228 2Q99 2 64 0H49Q43 6 43 9T45 27Q49 40 55 46H83H94Q174 46 189 55Q190 56 191 56Q196 59 201 76T241 233Q258 301 269 344Q339 619 339 625Q339 630 310 630H279Q212 630 191 624Q146 614 121 583T67 467Q60 445 57 441T43 437H40Z"></path></g><g data-mml-node="mi" transform="translate(977,-257.7) scale(0.707)"><path data-c="1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g></g><g data-mml-node="mo" transform="translate(9306.6,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="msub" transform="translate(9695.6,0)"><g data-mml-node="mi"><path data-c="1D44A" d="M436 683Q450 683 486 682T553 680Q604 680 638 681T677 682Q695 682 695 674Q695 670 692 659Q687 641 683 639T661 637Q636 636 621 632T600 624T597 615Q597 603 613 377T629 138L631 141Q633 144 637 151T649 170T666 200T690 241T720 295T759 362Q863 546 877 572T892 604Q892 619 873 628T831 637Q817 637 817 647Q817 650 819 660Q823 676 825 679T839 682Q842 682 856 682T895 682T949 681Q1015 681 1034 683Q1048 683 1048 672Q1048 666 1045 655T1038 640T1028 637Q1006 637 988 631T958 617T939 600T927 584L923 578L754 282Q586 -14 585 -15Q579 -22 561 -22Q546 -22 542 -17Q539 -14 523 229T506 480L494 462Q472 425 366 239Q222 -13 220 -15T215 -19Q210 -22 197 -22Q178 -22 176 -15Q176 -12 154 304T131 622Q129 631 121 633T82 637H58Q51 644 51 648Q52 671 64 683H76Q118 680 176 680Q301 680 313 683H323Q329 677 329 674T327 656Q322 641 318 637H297Q236 634 232 620Q262 160 266 136L501 550L499 587Q496 629 489 632Q483 636 447 637Q428 637 422 639T416 648Q416 650 418 660Q419 664 420 669T421 676T424 680T428 682T436 683Z"></path></g><g data-mml-node="mi" transform="translate(977,-150) scale(0.707)"><path data-c="1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g></g><g data-mml-node="mi" transform="translate(11090.3,0)"><path data-c="1D481" d="M223 430Q192 430 192 448Q192 450 225 561T261 677Q265 683 270 684Q273 686 534 686Q796 686 797 685Q805 682 805 673Q805 668 804 661T800 648T798 641Q796 637 531 352L266 67L329 66H364Q412 66 446 70T523 96T596 157Q617 186 630 220T649 273T663 297Q667 299 684 299H688Q715 299 715 281Q715 278 673 145T628 8Q626 4 617 0H348Q289 0 221 0T139 -1Q112 -1 99 -1T78 1T69 5T68 12Q68 16 71 31T77 49L84 57Q91 65 104 79T133 110T170 151T213 196L610 624H540Q533 624 514 624T488 624T467 623T443 620T422 616T398 609T373 600Q292 560 255 449Q251 436 246 433T223 430Z"></path></g><g data-mml-node="mo" transform="translate(12117.6,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mi" transform="translate(13117.8,0)"><path data-c="1D47F" d="M931 686Q953 686 953 670Q953 650 944 632Q936 624 924 624H914Q823 624 803 611Q800 609 696 503T591 396Q591 394 667 229L743 62H787H814Q846 62 846 44Q843 7 829 2Q825 0 817 0Q813 0 775 1T664 2Q590 2 551 1T508 0H507Q484 0 484 18Q484 19 488 37Q492 56 497 58T534 62L566 63Q567 64 520 169T471 274Q469 274 369 172T268 67L315 62Q320 62 328 62L335 61Q347 58 347 44Q344 10 331 2L326 0L287 1Q263 2 177 2Q95 2 78 1L53 0Q38 6 38 17Q38 40 50 57Q56 62 78 62Q169 62 188 75Q194 77 435 324L444 334L439 347Q437 351 373 492L313 624H268H246Q220 624 212 632Q210 636 210 642Q210 655 215 669T227 684Q230 686 247 686Q295 684 398 684Q438 684 472 684T527 685T551 686Q567 686 572 671Q572 667 568 651Q563 631 558 628T523 624T492 623H488L526 540Q563 457 564 457Q564 456 574 466T604 496T645 537L724 619Q716 622 677 624H673Q645 624 645 640Q645 660 654 678Q659 683 666 686L704 685Q728 684 813 684Q847 684 873 684T913 685T931 686Z"></path></g><g data-mml-node="mo" transform="translate(14064.8,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(14453.8,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></svg></mjx-container></span></p>
<p>只要把里面展开再合并同类项即可有</p>
<p><span class="math display"><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="30.506ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 13483.8 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D481" d="M223 430Q192 430 192 448Q192 450 225 561T261 677Q265 683 270 684Q273 686 534 686Q796 686 797 685Q805 682 805 673Q805 668 804 661T800 648T798 641Q796 637 531 352L266 67L329 66H364Q412 66 446 70T523 96T596 157Q617 186 630 220T649 273T663 297Q667 299 684 299H688Q715 299 715 281Q715 278 673 145T628 8Q626 4 617 0H348Q289 0 221 0T139 -1Q112 -1 99 -1T78 1T69 5T68 12Q68 16 71 31T77 49L84 57Q91 65 104 79T133 110T170 151T213 196L610 624H540Q533 624 514 624T488 624T467 623T443 620T422 616T398 609T373 600Q292 560 255 449Q251 436 246 433T223 430Z"></path></g><g data-mml-node="mo" transform="translate(805,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(1194,0)"><path data-c="1D458" d="M121 647Q121 657 125 670T137 683Q138 683 209 688T282 694Q294 694 294 686Q294 679 244 477Q194 279 194 272Q213 282 223 291Q247 309 292 354T362 415Q402 442 438 442Q468 442 485 423T503 369Q503 344 496 327T477 302T456 291T438 288Q418 288 406 299T394 328Q394 353 410 369T442 390L458 393Q446 405 434 405H430Q398 402 367 380T294 316T228 255Q230 254 243 252T267 246T293 238T320 224T342 206T359 180T365 147Q365 130 360 106T354 66Q354 26 381 26Q429 26 459 145Q461 153 479 153H483Q499 153 499 144Q499 139 496 130Q455 -11 378 -11Q333 -11 305 15T277 90Q277 108 280 121T283 145Q283 167 269 183T234 206T200 217T182 220H180Q168 178 159 139T145 81T136 44T129 20T122 7T111 -2Q98 -11 83 -11Q66 -11 57 -1T48 16Q48 26 85 176T158 471L195 616Q196 629 188 632T149 637H144Q134 637 131 637T124 640T121 647Z"></path></g><g data-mml-node="mo" transform="translate(1937.2,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="mn" transform="translate(2937.4,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g><g data-mml-node="mo" transform="translate(3437.4,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(4104.2,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="msub" transform="translate(5160,0)"><g data-mml-node="mi"><path data-c="210E" d="M137 683Q138 683 209 688T282 694Q294 694 294 685Q294 674 258 534Q220 386 220 383Q220 381 227 388Q288 442 357 442Q411 442 444 415T478 336Q478 285 440 178T402 50Q403 36 407 31T422 26Q450 26 474 56T513 138Q516 149 519 151T535 153Q555 153 555 145Q555 144 551 130Q535 71 500 33Q466 -10 419 -10H414Q367 -10 346 17T325 74Q325 90 361 192T398 345Q398 404 354 404H349Q266 404 205 306L198 293L164 158Q132 28 127 16Q114 -11 83 -11Q69 -11 59 -2T48 16Q48 30 121 320L195 616Q195 629 188 632T149 637H128Q122 643 122 645T124 664Q129 683 137 683Z"></path></g><g data-mml-node="TeXAtom" transform="translate(609,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D703" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path></g></g></g><g data-mml-node="mo" transform="translate(6150.6,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="msub" transform="translate(6539.6,0)"><g data-mml-node="mi"><path data-c="1D47E" d="M111 624Q109 624 102 624T91 623Q61 623 61 640Q61 660 70 678Q78 686 98 686Q140 684 239 684Q277 684 309 684T360 685T383 686H385Q407 686 407 668Q404 634 391 626Q387 624 348 624Q307 624 307 622Q307 618 332 409Q359 198 359 195L570 532L564 576L558 622V624H522H504Q472 624 472 641Q475 678 488 684L493 686L529 685Q551 684 645 684Q716 684 753 685T795 686Q818 686 818 669Q815 632 802 626Q798 624 759 624Q718 624 718 622Q718 615 743 410Q770 199 770 196Q770 195 806 253T903 406Q1035 618 1035 619Q1025 624 968 624Q943 624 943 641Q943 648 946 659Q950 675 952 679T963 686L998 685Q1020 684 1093 684Q1113 684 1139 685T1173 686Q1207 686 1207 669Q1207 664 1204 652Q1199 631 1194 628T1164 624Q1113 622 1101 615Q1098 612 905 305Q715 -1 709 -7Q699 -17 673 -17Q645 -17 639 -8L581 441Q581 444 442 221Q331 44 314 18T288 -14Q279 -17 263 -17H254Q229 -17 227 -5Q225 2 186 311L147 620V624H111Z"></path></g><g data-mml-node="mi" transform="translate(1126,-150) scale(0.707)"><path data-c="1D486" d="M260 -8Q196 -8 151 9T83 54T52 111T42 169Q42 188 44 210Q50 240 58 266Q127 434 335 451L338 452Q342 452 345 452Q347 452 353 452T363 451Q426 451 464 424T502 352Q502 289 442 250Q381 211 222 211H184Q184 210 181 196T175 162T171 126Q171 43 264 43Q391 43 457 105Q472 120 480 117Q486 114 497 102T509 83Q509 79 502 70T477 47T432 21T360 1T260 -8ZM237 262Q427 266 427 349Q427 368 409 384T354 401Q316 401 287 388T242 354T216 314T202 278L197 263Q197 262 237 262Z"></path></g></g><g data-mml-node="mi" transform="translate(8107.4,0)"><path data-c="1D47F" d="M931 686Q953 686 953 670Q953 650 944 632Q936 624 924 624H914Q823 624 803 611Q800 609 696 503T591 396Q591 394 667 229L743 62H787H814Q846 62 846 44Q843 7 829 2Q825 0 817 0Q813 0 775 1T664 2Q590 2 551 1T508 0H507Q484 0 484 18Q484 19 488 37Q492 56 497 58T534 62L566 63Q567 64 520 169T471 274Q469 274 369 172T268 67L315 62Q320 62 328 62L335 61Q347 58 347 44Q344 10 331 2L326 0L287 1Q263 2 177 2Q95 2 78 1L53 0Q38 6 38 17Q38 40 50 57Q56 62 78 62Q169 62 188 75Q194 77 435 324L444 334L439 347Q437 351 373 492L313 624H268H246Q220 624 212 632Q210 636 210 642Q210 655 215 669T227 684Q230 686 247 686Q295 684 398 684Q438 684 472 684T527 685T551 686Q567 686 572 671Q572 667 568 651Q563 631 558 628T523 624T492 623H488L526 540Q563 457 564 457Q564 456 574 466T604 496T645 537L724 619Q716 622 677 624H673Q645 624 645 640Q645 660 654 678Q659 683 666 686L704 685Q728 684 813 684Q847 684 873 684T913 685T931 686Z"></path></g><g data-mml-node="mo" transform="translate(9276.6,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="mi" transform="translate(10276.8,0)"><path data-c="1D47A" d="M354 45Q429 45 467 91T506 184Q506 225 477 250Q461 262 384 279T294 300Q238 318 210 362T182 452Q182 493 202 540T257 623Q338 702 449 702Q491 702 501 701Q571 690 610 654Q614 649 617 650Q618 650 650 675T683 702Q685 703 692 703Q714 703 714 690Q714 686 687 578T658 466Q653 458 629 458Q606 458 602 463Q600 465 599 466Q599 467 599 469T598 473Q598 475 599 487T600 511Q600 584 557 614T454 645Q386 645 347 606T308 520Q308 506 311 496T323 477T338 464T360 454T384 446T413 439T441 433Q523 416 549 401Q581 384 602 352Q631 309 631 254Q631 214 615 170T567 83T478 12T347 -16Q322 -16 300 -14T261 -8T230 0T205 10T187 20T172 30L162 37L130 11Q124 7 119 3T110 -4T104 -9T100 -13T96 -15T93 -16T91 -17T88 -17H82Q76 -17 73 -16T69 -14T66 -10T63 -5L90 107Q97 133 106 170Q116 211 120 219T136 228H148Q167 228 173 227T179 218Q179 216 176 200T173 168Q173 102 227 74T354 45Z"></path></g><g data-mml-node="mi" transform="translate(10990.8,0)"><path data-c="1D481" d="M223 430Q192 430 192 448Q192 450 225 561T261 677Q265 683 270 684Q273 686 534 686Q796 686 797 685Q805 682 805 673Q805 668 804 661T800 648T798 641Q796 637 531 352L266 67L329 66H364Q412 66 446 70T523 96T596 157Q617 186 630 220T649 273T663 297Q667 299 684 299H688Q715 299 715 281Q715 278 673 145T628 8Q626 4 617 0H348Q289 0 221 0T139 -1Q112 -1 99 -1T78 1T69 5T68 12Q68 16 71 31T77 49L84 57Q91 65 104 79T133 110T170 151T213 196L610 624H540Q533 624 514 624T488 624T467 623T443 620T422 616T398 609T373 600Q292 560 255 449Q251 436 246 433T223 430Z"></path></g><g data-mml-node="mo" transform="translate(11795.8,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(12184.8,0)"><path data-c="1D458" d="M121 647Q121 657 125 670T137 683Q138 683 209 688T282 694Q294 694 294 686Q294 679 244 477Q194 279 194 272Q213 282 223 291Q247 309 292 354T362 415Q402 442 438 442Q468 442 485 423T503 369Q503 344 496 327T477 302T456 291T438 288Q418 288 406 299T394 328Q394 353 410 369T442 390L458 393Q446 405 434 405H430Q398 402 367 380T294 316T228 255Q230 254 243 252T267 246T293 238T320 224T342 206T359 180T365 147Q365 130 360 106T354 66Q354 26 381 26Q429 26 459 145Q461 153 479 153H483Q499 153 499 144Q499 139 496 130Q455 -11 378 -11Q333 -11 305 15T277 90Q277 108 280 121T283 145Q283 167 269 183T234 206T200 217T182 220H180Q168 178 159 139T145 81T136 44T129 20T122 7T111 -2Q98 -11 83 -11Q66 -11 57 -1T48 16Q48 26 85 176T158 471L195 616Q196 629 188 632T149 637H144Q134 637 131 637T124 640T121 647Z"></path></g><g data-mml-node="mo" transform="translate(12705.8,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(13094.8,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></svg></mjx-container></span></p>
<p>其中<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="4.001ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 1768.6 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="210E" d="M137 683Q138 683 209 688T282 694Q294 694 294 685Q294 674 258 534Q220 386 220 383Q220 381 227 388Q288 442 357 442Q411 442 444 415T478 336Q478 285 440 178T402 50Q403 36 407 31T422 26Q450 26 474 56T513 138Q516 149 519 151T535 153Q555 153 555 145Q555 144 551 130Q535 71 500 33Q466 -10 419 -10H414Q367 -10 346 17T325 74Q325 90 361 192T398 345Q398 404 354 404H349Q266 404 205 306L198 293L164 158Q132 28 127 16Q114 -11 83 -11Q69 -11 59 -2T48 16Q48 30 121 320L195 616Q195 629 188 632T149 637H128Q122 643 122 645T124 664Q129 683 137 683Z"></path></g><g data-mml-node="mi" transform="translate(609,-150) scale(0.707)"><path data-c="1D703" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path></g></g><g data-mml-node="mo" transform="translate(990.6,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mo" transform="translate(1379.6,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></svg></mjx-container></span>可以看成是ReLu函数左半部分由右半部分中心对称得到的。而这个阈值<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.781ex;" xmlns="http://www.w3.org/2000/svg" width="6.163ex" height="2.379ex" role="img" focusable="false" viewBox="0 -706.5 2724.1 1051.5"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D703" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path></g><g data-mml-node="mo" transform="translate(746.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mfrac" transform="translate(1802.6,0)"><g data-mml-node="mi" transform="translate(234.5,394) scale(0.707)"><path data-c="1D6FC" d="M34 156Q34 270 120 356T309 442Q379 442 421 402T478 304Q484 275 485 237V208Q534 282 560 374Q564 388 566 390T582 393Q603 393 603 385Q603 376 594 346T558 261T497 161L486 147L487 123Q489 67 495 47T514 26Q528 28 540 37T557 60Q559 67 562 68T577 70Q597 70 597 62Q597 56 591 43Q579 19 556 5T512 -10H505Q438 -10 414 62L411 69L400 61Q390 53 370 41T325 18T267 -2T203 -11Q124 -11 79 39T34 156ZM208 26Q257 26 306 47T379 90L403 112Q401 255 396 290Q382 405 304 405Q235 405 183 332Q156 292 139 224T121 120Q121 71 146 49T208 26Z"></path></g><g data-mml-node="mi" transform="translate(220,-345) scale(0.707)"><path data-c="1D43F" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 217 683Q271 680 344 680Q485 680 506 683H518Q524 677 524 674T522 656Q517 641 513 637H475Q406 636 394 628Q387 624 380 600T313 336Q297 271 279 198T252 88L243 52Q243 48 252 48T311 46H328Q360 46 379 47T428 54T478 72T522 106T564 161Q580 191 594 228T611 270Q616 273 628 273H641Q647 264 647 262T627 203T583 83T557 9Q555 4 553 3T537 0T494 -1Q483 -1 418 -1T294 0H116Q32 0 32 10Q32 17 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z"></path></g><rect width="681.5" height="60" x="120" y="220"></rect></g></g></g></svg></mjx-container></span></p>
<img src="/2023/09/26/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-ISTA%E5%92%8CLISTA/pic1.png" class="">
<p>通过这样一次次迭代，那么就能进行稀疏编码的求解。这个算法的大致框图和伪代码如下</p>
<img src="/2023/09/26/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-ISTA%E5%92%8CLISTA/pic2.png" class="">
<img src="/2023/09/26/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-ISTA%E5%92%8CLISTA/pic3.png" class="">
<p>**需要注意，ISTA算法仅仅求解了最佳的稀疏编码，是不能去求解<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.352ex;" xmlns="http://www.w3.org/2000/svg" width="3.637ex" height="1.904ex" role="img" focusable="false" viewBox="0 -686 1607.3 841.7"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D47E" d="M111 624Q109 624 102 624T91 623Q61 623 61 640Q61 660 70 678Q78 686 98 686Q140 684 239 684Q277 684 309 684T360 685T383 686H385Q407 686 407 668Q404 634 391 626Q387 624 348 624Q307 624 307 622Q307 618 332 409Q359 198 359 195L570 532L564 576L558 622V624H522H504Q472 624 472 641Q475 678 488 684L493 686L529 685Q551 684 645 684Q716 684 753 685T795 686Q818 686 818 669Q815 632 802 626Q798 624 759 624Q718 624 718 622Q718 615 743 410Q770 199 770 196Q770 195 806 253T903 406Q1035 618 1035 619Q1025 624 968 624Q943 624 943 641Q943 648 946 659Q950 675 952 679T963 686L998 685Q1020 684 1093 684Q1113 684 1139 685T1173 686Q1207 686 1207 669Q1207 664 1204 652Q1199 631 1194 628T1164 624Q1113 622 1101 615Q1098 612 905 305Q715 -1 709 -7Q699 -17 673 -17Q645 -17 639 -8L581 441Q581 444 442 221Q331 44 314 18T288 -14Q279 -17 263 -17H254Q229 -17 227 -5Q225 2 186 311L147 620V624H111Z"></path></g><g data-mml-node="mi" transform="translate(1126,-150) scale(0.707)"><path data-c="1D485" d="M222 -8Q140 -8 89 34T38 158Q38 220 68 285T151 391Q230 452 329 452Q382 452 416 428L422 424Q423 424 447 523L472 622H468Q467 622 463 622T453 623T441 624T430 624T420 624T415 625Q403 628 403 642Q403 647 407 661T413 679Q417 684 428 685T504 690Q577 694 591 694Q608 694 612 679L467 91Q466 87 466 72Q466 43 483 43Q518 43 541 134Q546 155 550 158T571 162H576H587Q607 162 607 148Q606 142 604 132T590 94T566 47T528 9T474 -8Q396 -8 358 40Q295 -8 222 -8ZM404 351Q383 401 324 401Q300 401 270 385T221 330Q206 296 186 220Q166 136 166 106Q166 72 184 58T228 43Q256 43 284 57T328 84T343 103Q343 106 374 228L404 351Z"></path></g></g></g></g></svg></mjx-container></span>的</p>
<h3 id="lista">LISTA</h3>
<p>LISTA则是增加了深度学习的ISTA算法，可以看成是很多个全连接块拼接在一起得到的。</p>
<img src="/2023/09/26/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-ISTA%E5%92%8CLISTA/pic4.png" class="">
<p>而LISTA算法则可以看成是学习出所有的<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.352ex;" xmlns="http://www.w3.org/2000/svg" width="3.547ex" height="1.904ex" role="img" focusable="false" viewBox="0 -686 1567.7 841.7"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D47E" d="M111 624Q109 624 102 624T91 623Q61 623 61 640Q61 660 70 678Q78 686 98 686Q140 684 239 684Q277 684 309 684T360 685T383 686H385Q407 686 407 668Q404 634 391 626Q387 624 348 624Q307 624 307 622Q307 618 332 409Q359 198 359 195L570 532L564 576L558 622V624H522H504Q472 624 472 641Q475 678 488 684L493 686L529 685Q551 684 645 684Q716 684 753 685T795 686Q818 686 818 669Q815 632 802 626Q798 624 759 624Q718 624 718 622Q718 615 743 410Q770 199 770 196Q770 195 806 253T903 406Q1035 618 1035 619Q1025 624 968 624Q943 624 943 641Q943 648 946 659Q950 675 952 679T963 686L998 685Q1020 684 1093 684Q1113 684 1139 685T1173 686Q1207 686 1207 669Q1207 664 1204 652Q1199 631 1194 628T1164 624Q1113 622 1101 615Q1098 612 905 305Q715 -1 709 -7Q699 -17 673 -17Q645 -17 639 -8L581 441Q581 444 442 221Q331 44 314 18T288 -14Q279 -17 263 -17H254Q229 -17 227 -5Q225 2 186 311L147 620V624H111Z"></path></g><g data-mml-node="mi" transform="translate(1126,-150) scale(0.707)"><path data-c="1D486" d="M260 -8Q196 -8 151 9T83 54T52 111T42 169Q42 188 44 210Q50 240 58 266Q127 434 335 451L338 452Q342 452 345 452Q347 452 353 452T363 451Q426 451 464 424T502 352Q502 289 442 250Q381 211 222 211H184Q184 210 181 196T175 162T171 126Q171 43 264 43Q391 43 457 105Q472 120 480 117Q486 114 497 102T509 83Q509 79 502 70T477 47T432 21T360 1T260 -8ZM237 262Q427 266 427 349Q427 368 409 384T354 401Q316 401 287 388T242 354T216 314T202 278L197 263Q197 262 237 262Z"></path></g></g></g></g></svg></mjx-container></span>和<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.038ex;" xmlns="http://www.w3.org/2000/svg" width="1.615ex" height="1.629ex" role="img" focusable="false" viewBox="0 -703 714 720"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D47A" d="M354 45Q429 45 467 91T506 184Q506 225 477 250Q461 262 384 279T294 300Q238 318 210 362T182 452Q182 493 202 540T257 623Q338 702 449 702Q491 702 501 701Q571 690 610 654Q614 649 617 650Q618 650 650 675T683 702Q685 703 692 703Q714 703 714 690Q714 686 687 578T658 466Q653 458 629 458Q606 458 602 463Q600 465 599 466Q599 467 599 469T598 473Q598 475 599 487T600 511Q600 584 557 614T454 645Q386 645 347 606T308 520Q308 506 311 496T323 477T338 464T360 454T384 446T413 439T441 433Q523 416 549 401Q581 384 602 352Q631 309 631 254Q631 214 615 170T567 83T478 12T347 -16Q322 -16 300 -14T261 -8T230 0T205 10T187 20T172 30L162 37L130 11Q124 7 119 3T110 -4T104 -9T100 -13T96 -15T93 -16T91 -17T88 -17H82Q76 -17 73 -16T69 -14T66 -10T63 -5L90 107Q97 133 106 170Q116 211 120 219T136 228H148Q167 228 173 227T179 218Q179 216 176 200T173 168Q173 102 227 74T354 45Z"></path></g></g></g></svg></mjx-container></span>，然后通过这些参数来进行稀疏编码的求解。</p>
<p>由于是学习的算法，所以自然涉及到前向推断和反向传播的过程。</p>
<h4 id="前向传播">前向传播</h4>
<p>前向传播与ISTA算法基本一致，基本上就是和之前一样的步骤，来求出优化解。</p>
<img src="/2023/09/26/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-ISTA%E5%92%8CLISTA/pic5.png" class="">
<p>值得注意的是，这里面看起来也是在不断进行迭代，但是这个迭代的<strong>目的是求解出编码</strong>；模型的下降则是在反向传播中进行的。</p>
<p>可以这样理解，反向传播中的梯度下降是对<strong>模型进行调节</strong>，使得模型大体上能够符合训练集的分布；而前向传播中的下降则是对<strong>编码进行调节</strong>，求解的是参数对于稀疏编码的最优损失函数的解。</p>
<p>换言之，这个algorithm 3就是在模型的总体分布已经被反向传播固定的情况下，通过迭代的方法来求解出对应的输入下的最优编码。</p>
<p><strong>还需要注意一点的就是，前向传播里计算的Z(t)、C(t)、B是同样会在反向传播中使用到</strong></p>
<h3 id="反向传播">反向传播</h3>
<p>LISTA的反向传播步可能是一个难点，我们先来看伪代码</p>
<img src="/2023/09/26/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-ISTA%E5%92%8CLISTA/pic6.png" class="">
<p>这里面的Z(t)、C(t)、B是之前前向传播计算出来的。而这个算法中的<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.452ex;" xmlns="http://www.w3.org/2000/svg" width="18.322ex" height="2.149ex" role="img" focusable="false" viewBox="0 -750 8098.5 950"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D6FF" d="M195 609Q195 656 227 686T302 717Q319 716 351 709T407 697T433 690Q451 682 451 662Q451 644 438 628T403 612Q382 612 348 641T288 671T249 657T235 628Q235 584 334 463Q401 379 401 292Q401 169 340 80T205 -10H198Q127 -10 83 36T36 153Q36 286 151 382Q191 413 252 434Q252 435 245 449T230 481T214 521T201 566T195 609ZM112 130Q112 83 136 55T204 27Q233 27 256 51T291 111T309 178T316 232Q316 267 309 298T295 344T269 400L259 396Q215 381 183 342T137 256T118 179T112 130Z"></path></g><g data-mml-node="mi" transform="translate(444,0)"><path data-c="1D44B" d="M42 0H40Q26 0 26 11Q26 15 29 27Q33 41 36 43T55 46Q141 49 190 98Q200 108 306 224T411 342Q302 620 297 625Q288 636 234 637H206Q200 643 200 645T202 664Q206 677 212 683H226Q260 681 347 681Q380 681 408 681T453 682T473 682Q490 682 490 671Q490 670 488 658Q484 643 481 640T465 637Q434 634 411 620L488 426L541 485Q646 598 646 610Q646 628 622 635Q617 635 609 637Q594 637 594 648Q594 650 596 664Q600 677 606 683H618Q619 683 643 683T697 681T738 680Q828 680 837 683H845Q852 676 852 672Q850 647 840 637H824Q790 636 763 628T722 611T698 593L687 584Q687 585 592 480L505 384Q505 383 536 304T601 142T638 56Q648 47 699 46Q734 46 734 37Q734 35 732 23Q728 7 725 4T711 1Q708 1 678 1T589 2Q528 2 496 2T461 1Q444 1 444 10Q444 11 446 25Q448 35 450 39T455 44T464 46T480 47T506 54Q523 62 523 64Q522 64 476 181L429 299Q241 95 236 84Q232 76 232 72Q232 53 261 47Q262 47 267 47T273 46Q276 46 277 46T280 45T283 42T284 35Q284 26 282 19Q279 6 276 4T261 1Q258 1 243 1T201 2T142 2Q64 2 42 0Z"></path></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(1296,0)"><g data-mml-node="mo"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">、</text></g></g><g data-mml-node="mi" transform="translate(2296,0)"><path data-c="1D6FF" d="M195 609Q195 656 227 686T302 717Q319 716 351 709T407 697T433 690Q451 682 451 662Q451 644 438 628T403 612Q382 612 348 641T288 671T249 657T235 628Q235 584 334 463Q401 379 401 292Q401 169 340 80T205 -10H198Q127 -10 83 36T36 153Q36 286 151 382Q191 413 252 434Q252 435 245 449T230 481T214 521T201 566T195 609ZM112 130Q112 83 136 55T204 27Q233 27 256 51T291 111T309 178T316 232Q316 267 309 298T295 344T269 400L259 396Q215 381 183 342T137 256T118 179T112 130Z"></path></g><g data-mml-node="msub" transform="translate(2740,0)"><g data-mml-node="mi"><path data-c="1D44A" d="M436 683Q450 683 486 682T553 680Q604 680 638 681T677 682Q695 682 695 674Q695 670 692 659Q687 641 683 639T661 637Q636 636 621 632T600 624T597 615Q597 603 613 377T629 138L631 141Q633 144 637 151T649 170T666 200T690 241T720 295T759 362Q863 546 877 572T892 604Q892 619 873 628T831 637Q817 637 817 647Q817 650 819 660Q823 676 825 679T839 682Q842 682 856 682T895 682T949 681Q1015 681 1034 683Q1048 683 1048 672Q1048 666 1045 655T1038 640T1028 637Q1006 637 988 631T958 617T939 600T927 584L923 578L754 282Q586 -14 585 -15Q579 -22 561 -22Q546 -22 542 -17Q539 -14 523 229T506 480L494 462Q472 425 366 239Q222 -13 220 -15T215 -19Q210 -22 197 -22Q178 -22 176 -15Q176 -12 154 304T131 622Q129 631 121 633T82 637H58Q51 644 51 648Q52 671 64 683H76Q118 680 176 680Q301 680 313 683H323Q329 677 329 674T327 656Q322 641 318 637H297Q236 634 232 620Q262 160 266 136L501 550L499 587Q496 629 489 632Q483 636 447 637Q428 637 422 639T416 648Q416 650 418 660Q419 664 420 669T421 676T424 680T428 682T436 683Z"></path></g><g data-mml-node="mi" transform="translate(977,-150) scale(0.707)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(4096.5,0)"><g data-mml-node="mo"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">、</text></g></g><g data-mml-node="mi" transform="translate(5096.5,0)"><path data-c="1D6FF" d="M195 609Q195 656 227 686T302 717Q319 716 351 709T407 697T433 690Q451 682 451 662Q451 644 438 628T403 612Q382 612 348 641T288 671T249 657T235 628Q235 584 334 463Q401 379 401 292Q401 169 340 80T205 -10H198Q127 -10 83 36T36 153Q36 286 151 382Q191 413 252 434Q252 435 245 449T230 481T214 521T201 566T195 609ZM112 130Q112 83 136 55T204 27Q233 27 256 51T291 111T309 178T316 232Q316 267 309 298T295 344T269 400L259 396Q215 381 183 342T137 256T118 179T112 130Z"></path></g><g data-mml-node="mi" transform="translate(5540.5,0)"><path data-c="1D446" d="M308 24Q367 24 416 76T466 197Q466 260 414 284Q308 311 278 321T236 341Q176 383 176 462Q176 523 208 573T273 648Q302 673 343 688T407 704H418H425Q521 704 564 640Q565 640 577 653T603 682T623 704Q624 704 627 704T632 705Q645 705 645 698T617 577T585 459T569 456Q549 456 549 465Q549 471 550 475Q550 478 551 494T553 520Q553 554 544 579T526 616T501 641Q465 662 419 662Q362 662 313 616T263 510Q263 480 278 458T319 427Q323 425 389 408T456 390Q490 379 522 342T554 242Q554 216 546 186Q541 164 528 137T492 78T426 18T332 -20Q320 -22 298 -22Q199 -22 144 33L134 44L106 13Q83 -14 78 -18T65 -22Q52 -22 52 -14Q52 -11 110 221Q112 227 130 227H143Q149 221 149 216Q149 214 148 207T144 186T142 153Q144 114 160 87T203 47T255 29T308 24Z"></path></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(6185.5,0)"><g data-mml-node="mo"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">、</text></g></g><g data-mml-node="mi" transform="translate(7185.5,0)"><path data-c="1D6FF" d="M195 609Q195 656 227 686T302 717Q319 716 351 709T407 697T433 690Q451 682 451 662Q451 644 438 628T403 612Q382 612 348 641T288 671T249 657T235 628Q235 584 334 463Q401 379 401 292Q401 169 340 80T205 -10H198Q127 -10 83 36T36 153Q36 286 151 382Q191 413 252 434Q252 435 245 449T230 481T214 521T201 566T195 609ZM112 130Q112 83 136 55T204 27Q233 27 256 51T291 111T309 178T316 232Q316 267 309 298T295 344T269 400L259 396Q215 381 183 342T137 256T118 179T112 130Z"></path></g><g data-mml-node="mi" transform="translate(7629.5,0)"><path data-c="1D703" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path></g></g></g></svg></mjx-container></span>并不是需要用到的值，而是类似C语言那用用引用实现的多返回的写法。</p>
<p>首先使第一步中<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="19.506ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 8621.6 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D6FF" d="M195 609Q195 656 227 686T302 717Q319 716 351 709T407 697T433 690Q451 682 451 662Q451 644 438 628T403 612Q382 612 348 641T288 671T249 657T235 628Q235 584 334 463Q401 379 401 292Q401 169 340 80T205 -10H198Q127 -10 83 36T36 153Q36 286 151 382Q191 413 252 434Q252 435 245 449T230 481T214 521T201 566T195 609ZM112 130Q112 83 136 55T204 27Q233 27 256 51T291 111T309 178T316 232Q316 267 309 298T295 344T269 400L259 396Q215 381 183 342T137 256T118 179T112 130Z"></path></g><g data-mml-node="mi" transform="translate(444,0)"><path data-c="1D44D" d="M58 8Q58 23 64 35Q64 36 329 334T596 635L586 637Q575 637 512 637H500H476Q442 637 420 635T365 624T311 598T266 548T228 469Q227 466 226 463T224 458T223 453T222 450L221 448Q218 443 202 443Q185 443 182 453L214 561Q228 606 241 651Q249 679 253 681Q256 683 487 683H718Q723 678 723 675Q723 673 717 649Q189 54 188 52L185 49H274Q369 50 377 51Q452 60 500 100T579 247Q587 272 590 277T603 282H607Q628 282 628 271Q547 5 541 2Q538 0 300 0H124Q58 0 58 8Z"></path></g><g data-mml-node="mo" transform="translate(1167,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(1556,0)"><path data-c="1D447" d="M40 437Q21 437 21 445Q21 450 37 501T71 602L88 651Q93 669 101 677H569H659Q691 677 697 676T704 667Q704 661 687 553T668 444Q668 437 649 437Q640 437 637 437T631 442L629 445Q629 451 635 490T641 551Q641 586 628 604T573 629Q568 630 515 631Q469 631 457 630T439 622Q438 621 368 343T298 60Q298 48 386 46Q418 46 427 45T436 36Q436 31 433 22Q429 4 424 1L422 0Q419 0 415 0Q410 0 363 1T228 2Q99 2 64 0H49Q43 6 43 9T45 27Q49 40 55 46H83H94Q174 46 189 55Q190 56 191 56Q196 59 201 76T241 233Q258 301 269 344Q339 619 339 625Q339 630 310 630H279Q212 630 191 624Q146 614 121 583T67 467Q60 445 57 441T43 437H40Z"></path></g><g data-mml-node="mo" transform="translate(2260,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(2926.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mi" transform="translate(3982.6,0)"><path data-c="1D44D" d="M58 8Q58 23 64 35Q64 36 329 334T596 635L586 637Q575 637 512 637H500H476Q442 637 420 635T365 624T311 598T266 548T228 469Q227 466 226 463T224 458T223 453T222 450L221 448Q218 443 202 443Q185 443 182 453L214 561Q228 606 241 651Q249 679 253 681Q256 683 487 683H718Q723 678 723 675Q723 673 717 649Q189 54 188 52L185 49H274Q369 50 377 51Q452 60 500 100T579 247Q587 272 590 277T603 282H607Q628 282 628 271Q547 5 541 2Q538 0 300 0H124Q58 0 58 8Z"></path></g><g data-mml-node="mo" transform="translate(4705.6,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(5094.6,0)"><path data-c="1D447" d="M40 437Q21 437 21 445Q21 450 37 501T71 602L88 651Q93 669 101 677H569H659Q691 677 697 676T704 667Q704 661 687 553T668 444Q668 437 649 437Q640 437 637 437T631 442L629 445Q629 451 635 490T641 551Q641 586 628 604T573 629Q568 630 515 631Q469 631 457 630T439 622Q438 621 368 343T298 60Q298 48 386 46Q418 46 427 45T436 36Q436 31 433 22Q429 4 424 1L422 0Q419 0 415 0Q410 0 363 1T228 2Q99 2 64 0H49Q43 6 43 9T45 27Q49 40 55 46H83H94Q174 46 189 55Q190 56 191 56Q196 59 201 76T241 233Q258 301 269 344Q339 619 339 625Q339 630 310 630H279Q212 630 191 624Q146 614 121 583T67 467Q60 445 57 441T43 437H40Z"></path></g><g data-mml-node="mo" transform="translate(5798.6,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(6409.8,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="msup" transform="translate(7410,0)"><g data-mml-node="mi"><path data-c="1D44D" d="M58 8Q58 23 64 35Q64 36 329 334T596 635L586 637Q575 637 512 637H500H476Q442 637 420 635T365 624T311 598T266 548T228 469Q227 466 226 463T224 458T223 453T222 450L221 448Q218 443 202 443Q185 443 182 453L214 561Q228 606 241 651Q249 679 253 681Q256 683 487 683H718Q723 678 723 675Q723 673 717 649Q189 54 188 52L185 49H274Q369 50 377 51Q452 60 500 100T579 247Q587 272 590 277T603 282H607Q628 282 628 271Q547 5 541 2Q538 0 300 0H124Q58 0 58 8Z"></path></g><g data-mml-node="mo" transform="translate(808,363) scale(0.707)"><path data-c="2217" d="M229 286Q216 420 216 436Q216 454 240 464Q241 464 245 464T251 465Q263 464 273 456T283 436Q283 419 277 356T270 286L328 328Q384 369 389 372T399 375Q412 375 423 365T435 338Q435 325 425 315Q420 312 357 282T289 250L355 219L425 184Q434 175 434 161Q434 146 425 136T401 125Q393 125 383 131T328 171L270 213Q283 79 283 63Q283 53 276 44T250 35Q231 35 224 44T216 63Q216 80 222 143T229 213L171 171Q115 130 110 127Q106 124 100 124Q87 124 76 134T64 161Q64 166 64 169T67 175T72 181T81 188T94 195T113 204T138 215T170 230T210 250L74 315Q65 324 65 338Q65 353 74 363T98 374Q106 374 116 368T171 328L229 286Z"></path></g></g></g></g></svg></mjx-container></span>是为了求解出当前模型前向推断值和标签的误差，就宛若神经网络中的反向传播步骤一样。</p>
<p>但是由于在计算编码的时候需要进行多次的迭代操作，所以这里也需要从后向前依次计算，每次迭代都可以看成是经过了一次全连接的自己算，但是更新权重的时候所有需要更新的梯度最终都会被作用到一个神经元上。</p>
<p>当然，这里其实也只是理论上的分析可能会困难一点，<strong>实际上由于pytorch的自动求导的机制，实际写起来并没有很困难。</strong></p>
<p>下面来看一下这几个偏导在理论上是怎么求的。</p>
<p>已知前向传播的两个等式，分别记为等式1和等式2</p>
<p><span class="math display"><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="22.164ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 9796.4 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D46A" d="M380 -17Q335 -17 293 -10T207 16T130 65T76 144T55 256Q55 306 70 361T122 476T211 582T345 663T525 702H545Q673 702 731 634L777 668Q783 672 789 677T800 685T808 691T814 695T818 698T822 700T825 702T828 703T830 703T833 703Q855 703 855 690Q855 686 823 558T789 426Q786 421 782 420T756 419Q734 420 729 421T724 432Q724 434 725 447T726 472Q726 552 678 604Q640 640 586 640H574Q533 640 494 632T409 604T324 541T260 437Q243 397 227 333T210 219Q210 152 237 117Q255 90 299 68T420 46H429Q506 46 580 100T678 234Q683 249 687 251T712 254H723Q743 254 743 240Q743 232 736 213T710 162T663 100T586 40T477 -5Q433 -17 380 -17Z"></path></g><g data-mml-node="mo" transform="translate(855,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(1244,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(1605,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(2271.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mi" transform="translate(3327.6,0)"><path data-c="1D469" d="M258 624H235Q214 624 209 626T199 639Q203 678 216 684Q220 686 449 686H477H586Q684 686 733 677T817 634Q853 598 853 547Q853 499 826 460T761 401T695 371T654 360H653L662 358Q670 357 683 354T712 344T744 327T774 303T795 269T804 224Q804 148 732 79T533 1Q524 0 288 0H58Q47 5 43 15Q47 54 60 60Q64 62 113 62H162L302 623Q302 624 258 624ZM703 550Q703 571 695 586T675 609T656 619T643 623L545 624H447L417 504Q386 384 386 383T470 382Q554 383 565 385Q632 397 667 447T703 550ZM651 240Q651 265 645 282T626 309T608 322T592 329Q587 330 479 331H373L340 198Q307 65 306 64Q306 62 406 62L507 63L519 65Q565 76 596 107T639 171T651 240Z"></path></g><g data-mml-node="mo" transform="translate(4415.8,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="mi" transform="translate(5416,0)"><path data-c="1D47A" d="M354 45Q429 45 467 91T506 184Q506 225 477 250Q461 262 384 279T294 300Q238 318 210 362T182 452Q182 493 202 540T257 623Q338 702 449 702Q491 702 501 701Q571 690 610 654Q614 649 617 650Q618 650 650 675T683 702Q685 703 692 703Q714 703 714 690Q714 686 687 578T658 466Q653 458 629 458Q606 458 602 463Q600 465 599 466Q599 467 599 469T598 473Q598 475 599 487T600 511Q600 584 557 614T454 645Q386 645 347 606T308 520Q308 506 311 496T323 477T338 464T360 454T384 446T413 439T441 433Q523 416 549 401Q581 384 602 352Q631 309 631 254Q631 214 615 170T567 83T478 12T347 -16Q322 -16 300 -14T261 -8T230 0T205 10T187 20T172 30L162 37L130 11Q124 7 119 3T110 -4T104 -9T100 -13T96 -15T93 -16T91 -17T88 -17H82Q76 -17 73 -16T69 -14T66 -10T63 -5L90 107Q97 133 106 170Q116 211 120 219T136 228H148Q167 228 173 227T179 218Q179 216 176 200T173 168Q173 102 227 74T354 45Z"></path></g><g data-mml-node="mi" transform="translate(6130,0)"><path data-c="1D481" d="M223 430Q192 430 192 448Q192 450 225 561T261 677Q265 683 270 684Q273 686 534 686Q796 686 797 685Q805 682 805 673Q805 668 804 661T800 648T798 641Q796 637 531 352L266 67L329 66H364Q412 66 446 70T523 96T596 157Q617 186 630 220T649 273T663 297Q667 299 684 299H688Q715 299 715 281Q715 278 673 145T628 8Q626 4 617 0H348Q289 0 221 0T139 -1Q112 -1 99 -1T78 1T69 5T68 12Q68 16 71 31T77 49L84 57Q91 65 104 79T133 110T170 151T213 196L610 624H540Q533 624 514 624T488 624T467 623T443 620T422 616T398 609T373 600Q292 560 255 449Q251 436 246 433T223 430Z"></path></g><g data-mml-node="mo" transform="translate(6935,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(7324,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(7907.2,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mn" transform="translate(8907.4,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g><g data-mml-node="mo" transform="translate(9407.4,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></svg></mjx-container></span><br>
<span class="math display"><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="25.885ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 11441.4 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D481" d="M223 430Q192 430 192 448Q192 450 225 561T261 677Q265 683 270 684Q273 686 534 686Q796 686 797 685Q805 682 805 673Q805 668 804 661T800 648T798 641Q796 637 531 352L266 67L329 66H364Q412 66 446 70T523 96T596 157Q617 186 630 220T649 273T663 297Q667 299 684 299H688Q715 299 715 281Q715 278 673 145T628 8Q626 4 617 0H348Q289 0 221 0T139 -1Q112 -1 99 -1T78 1T69 5T68 12Q68 16 71 31T77 49L84 57Q91 65 104 79T133 110T170 151T213 196L610 624H540Q533 624 514 624T488 624T467 623T443 620T422 616T398 609T373 600Q292 560 255 449Q251 436 246 433T223 430Z"></path></g><g data-mml-node="mo" transform="translate(805,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(1194,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(1555,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(2221.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="msub" transform="translate(3277.6,0)"><g data-mml-node="mi"><path data-c="210E" d="M137 683Q138 683 209 688T282 694Q294 694 294 685Q294 674 258 534Q220 386 220 383Q220 381 227 388Q288 442 357 442Q411 442 444 415T478 336Q478 285 440 178T402 50Q403 36 407 31T422 26Q450 26 474 56T513 138Q516 149 519 151T535 153Q555 153 555 145Q555 144 551 130Q535 71 500 33Q466 -10 419 -10H414Q367 -10 346 17T325 74Q325 90 361 192T398 345Q398 404 354 404H349Q266 404 205 306L198 293L164 158Q132 28 127 16Q114 -11 83 -11Q69 -11 59 -2T48 16Q48 30 121 320L195 616Q195 629 188 632T149 637H128Q122 643 122 645T124 664Q129 683 137 683Z"></path></g><g data-mml-node="TeXAtom" transform="translate(609,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D703" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path></g></g></g><g data-mml-node="mo" transform="translate(4268.2,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="msub" transform="translate(4657.2,0)"><g data-mml-node="mi"><path data-c="1D47E" d="M111 624Q109 624 102 624T91 623Q61 623 61 640Q61 660 70 678Q78 686 98 686Q140 684 239 684Q277 684 309 684T360 685T383 686H385Q407 686 407 668Q404 634 391 626Q387 624 348 624Q307 624 307 622Q307 618 332 409Q359 198 359 195L570 532L564 576L558 622V624H522H504Q472 624 472 641Q475 678 488 684L493 686L529 685Q551 684 645 684Q716 684 753 685T795 686Q818 686 818 669Q815 632 802 626Q798 624 759 624Q718 624 718 622Q718 615 743 410Q770 199 770 196Q770 195 806 253T903 406Q1035 618 1035 619Q1025 624 968 624Q943 624 943 641Q943 648 946 659Q950 675 952 679T963 686L998 685Q1020 684 1093 684Q1113 684 1139 685T1173 686Q1207 686 1207 669Q1207 664 1204 652Q1199 631 1194 628T1164 624Q1113 622 1101 615Q1098 612 905 305Q715 -1 709 -7Q699 -17 673 -17Q645 -17 639 -8L581 441Q581 444 442 221Q331 44 314 18T288 -14Q279 -17 263 -17H254Q229 -17 227 -5Q225 2 186 311L147 620V624H111Z"></path></g><g data-mml-node="mi" transform="translate(1126,-150) scale(0.707)"><path data-c="1D486" d="M260 -8Q196 -8 151 9T83 54T52 111T42 169Q42 188 44 210Q50 240 58 266Q127 434 335 451L338 452Q342 452 345 452Q347 452 353 452T363 451Q426 451 464 424T502 352Q502 289 442 250Q381 211 222 211H184Q184 210 181 196T175 162T171 126Q171 43 264 43Q391 43 457 105Q472 120 480 117Q486 114 497 102T509 83Q509 79 502 70T477 47T432 21T360 1T260 -8ZM237 262Q427 266 427 349Q427 368 409 384T354 401Q316 401 287 388T242 354T216 314T202 278L197 263Q197 262 237 262Z"></path></g></g><g data-mml-node="mi" transform="translate(6224.9,0)"><path data-c="1D47F" d="M931 686Q953 686 953 670Q953 650 944 632Q936 624 924 624H914Q823 624 803 611Q800 609 696 503T591 396Q591 394 667 229L743 62H787H814Q846 62 846 44Q843 7 829 2Q825 0 817 0Q813 0 775 1T664 2Q590 2 551 1T508 0H507Q484 0 484 18Q484 19 488 37Q492 56 497 58T534 62L566 63Q567 64 520 169T471 274Q469 274 369 172T268 67L315 62Q320 62 328 62L335 61Q347 58 347 44Q344 10 331 2L326 0L287 1Q263 2 177 2Q95 2 78 1L53 0Q38 6 38 17Q38 40 50 57Q56 62 78 62Q169 62 188 75Q194 77 435 324L444 334L439 347Q437 351 373 492L313 624H268H246Q220 624 212 632Q210 636 210 642Q210 655 215 669T227 684Q230 686 247 686Q295 684 398 684Q438 684 472 684T527 685T551 686Q567 686 572 671Q572 667 568 651Q563 631 558 628T523 624T492 623H488L526 540Q563 457 564 457Q564 456 574 466T604 496T645 537L724 619Q716 622 677 624H673Q645 624 645 640Q645 660 654 678Q659 683 666 686L704 685Q728 684 813 684Q847 684 873 684T913 685T931 686Z"></path></g><g data-mml-node="mo" transform="translate(7394.1,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="mi" transform="translate(8394.4,0)"><path data-c="1D47A" d="M354 45Q429 45 467 91T506 184Q506 225 477 250Q461 262 384 279T294 300Q238 318 210 362T182 452Q182 493 202 540T257 623Q338 702 449 702Q491 702 501 701Q571 690 610 654Q614 649 617 650Q618 650 650 675T683 702Q685 703 692 703Q714 703 714 690Q714 686 687 578T658 466Q653 458 629 458Q606 458 602 463Q600 465 599 466Q599 467 599 469T598 473Q598 475 599 487T600 511Q600 584 557 614T454 645Q386 645 347 606T308 520Q308 506 311 496T323 477T338 464T360 454T384 446T413 439T441 433Q523 416 549 401Q581 384 602 352Q631 309 631 254Q631 214 615 170T567 83T478 12T347 -16Q322 -16 300 -14T261 -8T230 0T205 10T187 20T172 30L162 37L130 11Q124 7 119 3T110 -4T104 -9T100 -13T96 -15T93 -16T91 -17T88 -17H82Q76 -17 73 -16T69 -14T66 -10T63 -5L90 107Q97 133 106 170Q116 211 120 219T136 228H148Q167 228 173 227T179 218Q179 216 176 200T173 168Q173 102 227 74T354 45Z"></path></g><g data-mml-node="mi" transform="translate(9108.4,0)"><path data-c="1D481" d="M223 430Q192 430 192 448Q192 450 225 561T261 677Q265 683 270 684Q273 686 534 686Q796 686 797 685Q805 682 805 673Q805 668 804 661T800 648T798 641Q796 637 531 352L266 67L329 66H364Q412 66 446 70T523 96T596 157Q617 186 630 220T649 273T663 297Q667 299 684 299H688Q715 299 715 281Q715 278 673 145T628 8Q626 4 617 0H348Q289 0 221 0T139 -1Q112 -1 99 -1T78 1T69 5T68 12Q68 16 71 31T77 49L84 57Q91 65 104 79T133 110T170 151T213 196L610 624H540Q533 624 514 624T488 624T467 623T443 620T422 616T398 609T373 600Q292 560 255 449Q251 436 246 433T223 430Z"></path></g><g data-mml-node="mo" transform="translate(9913.4,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(10302.4,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(10663.4,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(11052.4,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></svg></mjx-container></span></p>
<p>对于<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.661ex;" xmlns="http://www.w3.org/2000/svg" width="22.233ex" height="2.378ex" role="img" focusable="false" viewBox="0 -759 9827.2 1051.2"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D6FF" d="M195 609Q195 656 227 686T302 717Q319 716 351 709T407 697T433 690Q451 682 451 662Q451 644 438 628T403 612Q382 612 348 641T288 671T249 657T235 628Q235 584 334 463Q401 379 401 292Q401 169 340 80T205 -10H198Q127 -10 83 36T36 153Q36 286 151 382Q191 413 252 434Q252 435 245 449T230 481T214 521T201 566T195 609ZM112 130Q112 83 136 55T204 27Q233 27 256 51T291 111T309 178T316 232Q316 267 309 298T295 344T269 400L259 396Q215 381 183 342T137 256T118 179T112 130Z"></path></g><g data-mml-node="mi" transform="translate(444,0)"><path data-c="1D436" d="M50 252Q50 367 117 473T286 641T490 704Q580 704 633 653Q642 643 648 636T656 626L657 623Q660 623 684 649Q691 655 699 663T715 679T725 690L740 705H746Q760 705 760 698Q760 694 728 561Q692 422 692 421Q690 416 687 415T669 413H653Q647 419 647 422Q647 423 648 429T650 449T651 481Q651 552 619 605T510 659Q484 659 454 652T382 628T299 572T226 479Q194 422 175 346T156 222Q156 108 232 58Q280 24 350 24Q441 24 512 92T606 240Q610 253 612 255T628 257Q648 257 648 248Q648 243 647 239Q618 132 523 55T319 -22Q206 -22 128 53T50 252Z"></path></g><g data-mml-node="mo" transform="translate(1204,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(1593,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(1954,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(2620.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="msubsup" transform="translate(3676.6,0)"><g data-mml-node="mi"><path data-c="210E" d="M137 683Q138 683 209 688T282 694Q294 694 294 685Q294 674 258 534Q220 386 220 383Q220 381 227 388Q288 442 357 442Q411 442 444 415T478 336Q478 285 440 178T402 50Q403 36 407 31T422 26Q450 26 474 56T513 138Q516 149 519 151T535 153Q555 153 555 145Q555 144 551 130Q535 71 500 33Q466 -10 419 -10H414Q367 -10 346 17T325 74Q325 90 361 192T398 345Q398 404 354 404H349Q266 404 205 306L198 293L164 158Q132 28 127 16Q114 -11 83 -11Q69 -11 59 -2T48 16Q48 30 121 320L195 616Q195 629 188 632T149 637H128Q122 643 122 645T124 664Q129 683 137 683Z"></path></g><g data-mml-node="mi" transform="translate(609,363) scale(0.707)"><path data-c="2032" d="M79 43Q73 43 52 49T30 61Q30 68 85 293T146 528Q161 560 198 560Q218 560 240 545T262 501Q262 496 260 486Q259 479 173 263T84 45T79 43Z"></path></g><g data-mml-node="mi" transform="translate(609,-285.1) scale(0.707)"><path data-c="1D703" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path></g></g><g data-mml-node="mo" transform="translate(4667.2,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(5056.2,0)"><path data-c="1D46A" d="M380 -17Q335 -17 293 -10T207 16T130 65T76 144T55 256Q55 306 70 361T122 476T211 582T345 663T525 702H545Q673 702 731 634L777 668Q783 672 789 677T800 685T808 691T814 695T818 698T822 700T825 702T828 703T830 703T833 703Q855 703 855 690Q855 686 823 558T789 426Q786 421 782 420T756 419Q734 420 729 421T724 432Q724 434 725 447T726 472Q726 552 678 604Q640 640 586 640H574Q533 640 494 632T409 604T324 541T260 437Q243 397 227 333T210 219Q210 152 237 117Q255 90 299 68T420 46H429Q506 46 580 100T678 234Q683 249 687 251T712 254H723Q743 254 743 240Q743 232 736 213T710 162T663 100T586 40T477 -5Q433 -17 380 -17Z"></path></g><g data-mml-node="mo" transform="translate(5911.2,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(6300.2,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(6661.2,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(7050.2,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mi" transform="translate(7439.2,0)"><path data-c="1D6FF" d="M195 609Q195 656 227 686T302 717Q319 716 351 709T407 697T433 690Q451 682 451 662Q451 644 438 628T403 612Q382 612 348 641T288 671T249 657T235 628Q235 584 334 463Q401 379 401 292Q401 169 340 80T205 -10H198Q127 -10 83 36T36 153Q36 286 151 382Q191 413 252 434Q252 435 245 449T230 481T214 521T201 566T195 609ZM112 130Q112 83 136 55T204 27Q233 27 256 51T291 111T309 178T316 232Q316 267 309 298T295 344T269 400L259 396Q215 381 183 342T137 256T118 179T112 130Z"></path></g><g data-mml-node="mi" transform="translate(7883.2,0)"><path data-c="1D481" d="M223 430Q192 430 192 448Q192 450 225 561T261 677Q265 683 270 684Q273 686 534 686Q796 686 797 685Q805 682 805 673Q805 668 804 661T800 648T798 641Q796 637 531 352L266 67L329 66H364Q412 66 446 70T523 96T596 157Q617 186 630 220T649 273T663 297Q667 299 684 299H688Q715 299 715 281Q715 278 673 145T628 8Q626 4 617 0H348Q289 0 221 0T139 -1Q112 -1 99 -1T78 1T69 5T68 12Q68 16 71 31T77 49L84 57Q91 65 104 79T133 110T170 151T213 196L610 624H540Q533 624 514 624T488 624T467 623T443 620T422 616T398 609T373 600Q292 560 255 449Q251 436 246 433T223 430Z"></path></g><g data-mml-node="mo" transform="translate(8688.2,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(9077.2,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(9438.2,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></svg></mjx-container></span>而言，只需要对等式2进行两边对<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="4.511ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 1994 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D46A" d="M380 -17Q335 -17 293 -10T207 16T130 65T76 144T55 256Q55 306 70 361T122 476T211 582T345 663T525 702H545Q673 702 731 634L777 668Q783 672 789 677T800 685T808 691T814 695T818 698T822 700T825 702T828 703T830 703T833 703Q855 703 855 690Q855 686 823 558T789 426Q786 421 782 420T756 419Q734 420 729 421T724 432Q724 434 725 447T726 472Q726 552 678 604Q640 640 586 640H574Q533 640 494 632T409 604T324 541T260 437Q243 397 227 333T210 219Q210 152 237 117Q255 90 299 68T420 46H429Q506 46 580 100T678 234Q683 249 687 251T712 254H723Q743 254 743 240Q743 232 736 213T710 162T663 100T586 40T477 -5Q433 -17 380 -17Z"></path></g><g data-mml-node="mo" transform="translate(855,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(1244,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(1605,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></svg></mjx-container></span>求偏导并变形即可。</p>
<p>而对于其他的梯度更新项而言，都是对于等式1中对应的位置求解偏导得到的。</p>
<p>此外，由于前向传播是从第0项(初始值)到第T项的前向计算，而反向传播的循环中仅仅求了从第T项到第1项的梯度，所以还需要额外求解一个第0项的更新，这样就得到了模型中的反向更新梯度。</p>
<h3 id="代码编写">代码编写</h3>
<p>代码参考了这篇<a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_38290475/article/details/104684232">博客</a>。</p>
<h4 id="ista-1">ISTA</h4>
<p>首先来编写一下ISTA算法，这里面的ISTA算法是用来作为LISTA算法的对比算法的，所以不需要编写反向传播的代码。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">ista</span>(<span class="params">X, W_d, a, L, max_iter, eps</span>):</span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    X是输入数据</span></span><br><span class="line"><span class="string">    W_d是字典编码数据</span></span><br><span class="line"><span class="string">    a是正则化项惩罚系数</span></span><br><span class="line"><span class="string">    L是Lipschitz常数</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">shrinkage</span>(<span class="params">x, theta</span>):</span><br><span class="line">        <span class="string">'''</span></span><br><span class="line"><span class="string">        闭包函数，软阈值</span></span><br><span class="line"><span class="string">        '''</span></span><br><span class="line">        <span class="keyword">return</span> np.multiply(np.sign(x), np.maximum(np.<span class="built_in">abs</span>(x) - theta, <span class="number">0</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 首先计算W_d^T*W_d的特征值，并保证Lipschitz常数大于最大特征值</span></span><br><span class="line">    eig, eig_vector = np.linalg.eig(W_d.T * W_d)</span><br><span class="line">    <span class="keyword">assert</span> L &gt; np.<span class="built_in">max</span>(eig)</span><br><span class="line">    <span class="keyword">del</span> eig, eig_vector</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 按照公式计算W_e</span></span><br><span class="line">    W_e = W_d.T / L</span><br><span class="line"></span><br><span class="line">    recon_errors = []</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 开始迭代计算出编码Z，设定一个种子</span></span><br><span class="line">    Z_old = np.zeros((W_d.shape[<span class="number">1</span>], <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(max_iter):</span><br><span class="line">        temp = W_d * Z_old - X</span><br><span class="line">        Z_new = shrinkage(Z_old - W_e * temp, a / L)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 如果两次迭代的差值小于eps，则停止迭代</span></span><br><span class="line">        <span class="keyword">if</span> np.<span class="built_in">sum</span>(np.<span class="built_in">abs</span>(Z_new - Z_old)) &lt;= eps:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">        Z_old = Z_new</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 计算重构误差</span></span><br><span class="line">        <span class="comment"># 需要加上正则化项</span></span><br><span class="line">        recon_error = np.linalg.norm(</span><br><span class="line">            X - W_d * Z_new, <span class="number">2</span>) ** <span class="number">2</span> + a * np.linalg.norm(Z_new, <span class="number">1</span>)</span><br><span class="line">        recon_errors.append(recon_error)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> Z_new, recon_errors</span><br></pre></td></tr></table></figure>
<p>简单验证一下，可以看到稀疏重建的效果，分别展示两个数据的重建效果</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> scipy.linalg <span class="keyword">import</span> orth</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">ista</span>(<span class="params">X, W_d, a, L, max_iter, eps</span>):</span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    X是输入数据</span></span><br><span class="line"><span class="string">    W_d是字典编码数据</span></span><br><span class="line"><span class="string">    a是正则化项惩罚系数</span></span><br><span class="line"><span class="string">    L是Lipschitz常数</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">shrinkage</span>(<span class="params">x, theta</span>):</span><br><span class="line">        <span class="string">'''</span></span><br><span class="line"><span class="string">        闭包函数，软阈值</span></span><br><span class="line"><span class="string">        '''</span></span><br><span class="line">        <span class="keyword">return</span> np.multiply(np.sign(x), np.maximum(np.<span class="built_in">abs</span>(x) - theta, <span class="number">0</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 首先计算W_d^T*W_d的特征值，并保证Lipschitz常数大于最大特征值</span></span><br><span class="line">    eig, eig_vector = np.linalg.eig(W_d.T * W_d)</span><br><span class="line">    <span class="keyword">assert</span> L &gt; np.<span class="built_in">max</span>(eig)</span><br><span class="line">    <span class="keyword">del</span> eig, eig_vector</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 按照公式计算W_e</span></span><br><span class="line">    W_e = W_d.T / L</span><br><span class="line"></span><br><span class="line">    recon_errors = []</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 开始迭代计算出编码Z，设定一个种子</span></span><br><span class="line">    Z_old = np.zeros((W_d.shape[<span class="number">1</span>], <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(max_iter):</span><br><span class="line">        temp = W_d * Z_old - X</span><br><span class="line">        Z_new = shrinkage(Z_old - W_e * temp, a / L)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 如果两次迭代的差值小于eps，则停止迭代</span></span><br><span class="line">        <span class="keyword">if</span> np.<span class="built_in">sum</span>(np.<span class="built_in">abs</span>(Z_new - Z_old)) &lt;= eps:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">        Z_old = Z_new</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 计算重构误差</span></span><br><span class="line">        <span class="comment"># 需要加上正则化项</span></span><br><span class="line">        recon_error = np.linalg.norm(</span><br><span class="line">            X - W_d * Z_new, <span class="number">2</span>) ** <span class="number">2</span>+a*np.linalg.norm(Z_new, <span class="number">1</span>)</span><br><span class="line">        recon_errors.append(recon_error)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f"index <span class="subst">{i}</span>: <span class="subst">{recon_error}</span>"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> Z_new, recon_errors</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 表示输入数据维度、输出数据维度、稀疏度</span></span><br><span class="line">m, n, k = <span class="number">1000</span>, <span class="number">256</span>, <span class="number">5</span></span><br><span class="line"><span class="comment"># 仅仅重建两个数据</span></span><br><span class="line">N = <span class="number">2</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 构建字典W_d，随机构建一个</span></span><br><span class="line">Psi = np.eye(m)</span><br><span class="line">Phi = np.random.randn(n, m)</span><br><span class="line">Phi = np.transpose(orth(np.transpose(Phi)))</span><br><span class="line">W_d = np.dot(Phi, Psi)</span><br><span class="line"><span class="built_in">print</span>(W_d.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成稀疏信号Z和测量X</span></span><br><span class="line">Z = np.zeros((N, m))</span><br><span class="line">X = np.zeros((N, n))</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(N):</span><br><span class="line">    index_k = np.random.choice(a=m, size=k, replace=<span class="literal">False</span>, p=<span class="literal">None</span>)</span><br><span class="line">    Z[i, index_k] = <span class="number">5</span> * np.random.randn(k, <span class="number">1</span>).reshape([-<span class="number">1</span>, ])</span><br><span class="line">    X[i] = np.dot(W_d, Z[i, :])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># ISTA算法，展示两个稀疏重建效果</span></span><br><span class="line">Z_recon, recon_errors = ista(np.mat(X).T, np.mat(W_d), <span class="number">0.1</span>, <span class="number">2</span>, <span class="number">1000</span>, <span class="number">0.002</span>)</span><br><span class="line">plt.subplot(<span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">plt.plot(Z_recon.T[<span class="number">0</span>].T, <span class="string">'--'</span>, label=<span class="string">'ISTA'</span>)</span><br><span class="line">plt.title(<span class="string">'1'</span>)</span><br><span class="line">plt.legend()</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">2</span>, <span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">plt.plot(Z_recon.T[<span class="number">1</span>].T, <span class="string">'--'</span>, label=<span class="string">'ISTA'</span>)</span><br><span class="line">plt.title(<span class="string">'2'</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<img src="/2023/09/26/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-ISTA%E5%92%8CLISTA/pic7.png" class="">
<h4 id="lista-1">LISTA</h4>
<p>然后看一下LISTA的算法，利用pytorch来编写，直接使用自动求导机制，不需要再额外计算雅可比乱七八糟的东西了。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> scipy.linalg <span class="keyword">import</span> orth</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line">device = torch.device(<span class="string">"cuda:0"</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">"cpu"</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LISTA</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, n, m, W_e, max_iter, L, theta</span>):</span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        n: 输入维度</span></span><br><span class="line"><span class="string">        m: 稀疏表示的维度</span></span><br><span class="line"><span class="string">        W_e: 字典</span></span><br><span class="line"><span class="string">        max_iter: 最大迭代次数</span></span><br><span class="line"><span class="string">        L: Lipschitz常数</span></span><br><span class="line"><span class="string">        theta: 阈值</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line"></span><br><span class="line">        <span class="built_in">super</span>(LISTA, self).__init__()</span><br><span class="line">        <span class="comment"># 构建两个全连接层，分别为W_e和S</span></span><br><span class="line">        self._W = nn.Linear(in_features=n, out_features=m, bias=<span class="literal">False</span>)</span><br><span class="line">        self._S = nn.Linear(in_features=m, out_features=m,</span><br><span class="line">                            bias=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">        self._S2 = nn.Linear(in_features=m, out_features=m,</span><br><span class="line">                             bias=<span class="literal">False</span>)</span><br><span class="line">        self._S3 = nn.Linear(in_features=m, out_features=m,</span><br><span class="line">                             bias=<span class="literal">False</span>)</span><br><span class="line">        <span class="comment"># 创建阈值函数，阈值为theta</span></span><br><span class="line">        self.shrinkage = nn.Softshrink(theta)</span><br><span class="line">        self.theta = theta</span><br><span class="line"></span><br><span class="line">        self.max_iter = max_iter</span><br><span class="line">        self.A = W_e</span><br><span class="line">        self.L = L</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">weights_init</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        按照伪代码来初始化S和W_e</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        A = self.A.cpu().numpy()</span><br><span class="line">        L = self.L</span><br><span class="line">        S = torch.from_numpy(np.eye(A.shape[<span class="number">1</span>]) - (<span class="number">1</span>/L)*np.matmul(A.T, A))</span><br><span class="line">        S = S.<span class="built_in">float</span>().to(device)</span><br><span class="line">        W = torch.from_numpy((<span class="number">1</span>/L)*A.T)</span><br><span class="line">        W = W.<span class="built_in">float</span>().to(device)</span><br><span class="line"></span><br><span class="line">        self._S.weight = nn.Parameter(S)</span><br><span class="line">        self._S2.weight = nn.Parameter(S)</span><br><span class="line">        self._S3.weight = nn.Parameter(S)</span><br><span class="line">        self._W.weight = nn.Parameter(W)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, y</span>):</span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        前向推断步，利用自动求导机制不需要再求解导数</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        x = self.shrinkage(self._W(y))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.max_iter == <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> <span class="built_in">iter</span> <span class="keyword">in</span> <span class="built_in">range</span>(self.max_iter):</span><br><span class="line">            <span class="comment"># 这是一个定长操作，且pytorch自动解决导数链，所以不需要额外保存信息</span></span><br><span class="line">            x = self.shrinkage(self._W(y) + self._S(x))</span><br><span class="line">            x = self.shrinkage(self._W(y) + self._S2(x))</span><br><span class="line">            x = self.shrinkage(self._W(y) + self._S3(x))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train_lista</span>(<span class="params">Y, dictionary, a, L, max_iter=<span class="number">30</span></span>):</span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    由于需要训练权重，所以还需要使用一个包装函数来训练网络</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    n, m = dictionary.shape</span><br><span class="line">    n_samples = Y.shape[<span class="number">0</span>]</span><br><span class="line">    batch_size = <span class="number">32</span></span><br><span class="line">    steps_per_epoch = n_samples // batch_size</span><br><span class="line"></span><br><span class="line">    Y = torch.from_numpy(Y)</span><br><span class="line">    Y = Y.<span class="built_in">float</span>().to(device)</span><br><span class="line"></span><br><span class="line">    W_d = torch.from_numpy(dictionary)</span><br><span class="line">    W_d = W_d.<span class="built_in">float</span>().to(device)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 构建网络</span></span><br><span class="line">    net = LISTA(n, m, W_d, max_iter=<span class="number">30</span>, L=L, theta=a/L)</span><br><span class="line">    net = net.<span class="built_in">float</span>().to(device)</span><br><span class="line">    net.weights_init()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 一些训练超参数</span></span><br><span class="line">    learning_rate = <span class="number">1e-2</span></span><br><span class="line">    criterion1 = nn.MSELoss()</span><br><span class="line">    criterion2 = nn.L1Loss()</span><br><span class="line">    all_zeros = torch.zeros(batch_size, m).to(device)</span><br><span class="line">    optimizer = torch.optim.SGD(</span><br><span class="line">        net.parameters(), lr=learning_rate,  momentum=<span class="number">0.9</span>)</span><br><span class="line"></span><br><span class="line">    loss_list = []</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">100</span>):</span><br><span class="line">        index_samples = np.random.choice(</span><br><span class="line">            a=n_samples, size=n_samples, replace=<span class="literal">False</span>, p=<span class="literal">None</span>)</span><br><span class="line">        Y_shuffle = Y[index_samples]</span><br><span class="line">        <span class="keyword">for</span> step <span class="keyword">in</span> <span class="built_in">range</span>(steps_per_epoch):</span><br><span class="line">            Y_batch = Y_shuffle[step*batch_size:(step+<span class="number">1</span>)*batch_size]</span><br><span class="line">            optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 计算输出</span></span><br><span class="line">            X_h = net(Y_batch)</span><br><span class="line">            Y_h = torch.mm(X_h, W_d.T)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 计算正则化loss</span></span><br><span class="line">            loss1 = criterion1(Y_batch.<span class="built_in">float</span>(), Y_h.<span class="built_in">float</span>())</span><br><span class="line">            loss2 = a * criterion2(X_h.<span class="built_in">float</span>(), all_zeros.<span class="built_in">float</span>())</span><br><span class="line">            loss = loss1 + loss2</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 自动求导更新模型</span></span><br><span class="line">            loss.backward()</span><br><span class="line">            optimizer.step()</span><br><span class="line"></span><br><span class="line">            <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">                loss_list.append(loss.detach().data)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">"epoch: {}, loss: {}"</span>.<span class="built_in">format</span>(epoch, loss.detach().data))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> net, loss_list</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 表示输入数据维度、输出数据维度、稀疏度</span></span><br><span class="line">m, n, k = <span class="number">1000</span>, <span class="number">256</span>, <span class="number">5</span></span><br><span class="line"><span class="comment"># 表示训练样本数，因为要训练，所以多一点</span></span><br><span class="line">N = <span class="number">128</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化字典</span></span><br><span class="line">Psi = np.eye(m)</span><br><span class="line">Phi = np.random.randn(n, m)</span><br><span class="line">Phi = np.transpose(orth(np.transpose(Phi)))</span><br><span class="line">W_d = np.dot(Phi, Psi)</span><br><span class="line"><span class="built_in">print</span>(W_d.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成数据</span></span><br><span class="line">Z = np.zeros((N, m))</span><br><span class="line">X = np.zeros((N, n))</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(N):</span><br><span class="line">    index_k = np.random.choice(a=m, size=k, replace=<span class="literal">False</span>, p=<span class="literal">None</span>)</span><br><span class="line">    Z[i, index_k] = <span class="number">5</span> * np.random.randn(k, <span class="number">1</span>).reshape([-<span class="number">1</span>, ])</span><br><span class="line">    X[i] = np.dot(W_d, Z[i, :])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算网络和loss</span></span><br><span class="line">net, err_list = train_lista(X, W_d, <span class="number">0.1</span>, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 推断并画出第一个样本和对应的稀疏表示</span></span><br><span class="line"></span><br><span class="line">X_h = net(torch.from_numpy(X[<span class="number">0</span>:<span class="number">2</span>]).<span class="built_in">float</span>().to(device))</span><br><span class="line">plt.subplot(<span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">plt.plot(X[<span class="number">0</span>])</span><br><span class="line">plt.title(<span class="string">"Original"</span>)</span><br><span class="line">plt.subplot(<span class="number">2</span>, <span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">plt.plot(X_h.cpu().detach().numpy()[<span class="number">0</span>], label=<span class="string">"reconstruction"</span>)</span><br><span class="line">plt.title(<span class="string">"Reconstruction"</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>这里搭建了具有3个block的网络来进行训练(也就是和之前出现的那个LISTA算法一样)</p>
<p>这里再详细说明一下<strong>生成数据的代码</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 生成数据</span></span><br><span class="line">m, n, k = <span class="number">1000</span>, <span class="number">256</span>, <span class="number">5</span></span><br><span class="line"></span><br><span class="line">Z = np.zeros((N, m))</span><br><span class="line">X = np.zeros((N, n))</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(N):</span><br><span class="line">    index_k = np.random.choice(a=m, size=k, replace=<span class="literal">False</span>, p=<span class="literal">None</span>)</span><br><span class="line">    Z[i, index_k] = <span class="number">5</span> * np.random.randn(k, <span class="number">1</span>).reshape([-<span class="number">1</span>, ])</span><br><span class="line">    X[i] = np.dot(W_d, Z[i, :])</span><br></pre></td></tr></table></figure>
<p>由于LISTA算法的目的是训练出参数，所以自然需要准备好训练数据，但是由于我们没有很好的数据集，所以这里就直接生成了一些数据。在生成数据时，是先创建好一个稀疏的Z(有k个元素为非0的稀疏向量)，然后再通过一个随机生成字典W_d来计算出X，这样就能够保证X和Z是具有对应关系的数据集。</p>
<p>可以看一下对应的重建效果，通过学习出<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.355ex;" xmlns="http://www.w3.org/2000/svg" width="3.155ex" height="1.901ex" role="img" focusable="false" viewBox="0 -683 1394.7 840.1"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D44A" d="M436 683Q450 683 486 682T553 680Q604 680 638 681T677 682Q695 682 695 674Q695 670 692 659Q687 641 683 639T661 637Q636 636 621 632T600 624T597 615Q597 603 613 377T629 138L631 141Q633 144 637 151T649 170T666 200T690 241T720 295T759 362Q863 546 877 572T892 604Q892 619 873 628T831 637Q817 637 817 647Q817 650 819 660Q823 676 825 679T839 682Q842 682 856 682T895 682T949 681Q1015 681 1034 683Q1048 683 1048 672Q1048 666 1045 655T1038 640T1028 637Q1006 637 988 631T958 617T939 600T927 584L923 578L754 282Q586 -14 585 -15Q579 -22 561 -22Q546 -22 542 -17Q539 -14 523 229T506 480L494 462Q472 425 366 239Q222 -13 220 -15T215 -19Q210 -22 197 -22Q178 -22 176 -15Q176 -12 154 304T131 622Q129 631 121 633T82 637H58Q51 644 51 648Q52 671 64 683H76Q118 680 176 680Q301 680 313 683H323Q329 677 329 674T327 656Q322 641 318 637H297Q236 634 232 620Q262 160 266 136L501 550L499 587Q496 629 489 632Q483 636 447 637Q428 637 422 639T416 648Q416 650 418 660Q419 664 420 669T421 676T424 680T428 682T436 683Z"></path></g><g data-mml-node="mi" transform="translate(977,-150) scale(0.707)"><path data-c="1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g></g></g></g></svg></mjx-container></span>，能够在一定程度上更好的完成重建的工作</p>
<img src="/2023/09/26/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-ISTA%E5%92%8CLISTA/pic8.png" class="">
<h3 id="总结">总结</h3>
<p>使用LISTA算法可以从一个预定义的集合中学习到特征的分布，而使用pytorch，并不需要我们去负责繁琐的求导步骤，只需要按照前向传播和反向传播的步骤来写就可以了，pytorch的自动求导可以很好的帮助我们计算出对应的导数并完成更新操作。</p>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/SLAM/" rel="tag"># SLAM</a>
              <a href="/tags/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/" rel="tag"># 论文阅读</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2023/09/19/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-%E5%9C%A8RANSAC%E4%B8%8B%E5%9F%BA%E4%BA%8EHC%E5%92%8CML%E7%9A%84%E4%BD%8D%E5%A7%BF%E4%BC%B0%E8%AE%A1%E6%9C%80%E5%B0%8F%E9%85%8D%E7%BD%AE%E9%97%AE%E9%A2%98/" rel="prev" title="论文阅读--在RANSAC下基于HC和ML的位姿估计最小配置问题">
      <i class="fa fa-chevron-left"></i> 论文阅读--在RANSAC下基于HC和ML的位姿估计最小配置问题
    </a></div>
      <div class="post-nav-item">
    <a href="/2023/10/10/%E5%AF%B9pnp%E9%97%AE%E9%A2%98end2end%E7%9A%84%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%AD%E7%BB%83%E6%96%B9%E6%B3%95/" rel="next" title="对pnp问题end2end的深度学习训练方法">
      对pnp问题end2end的深度学习训练方法 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          
    <div class="comments" id="valine-comments"></div>

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#learning-fast-approximations-of-sparse-coding"><span class="nav-number">1.</span> <span class="nav-text">Learning Fast Approximations of Sparse Coding</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#ista"><span class="nav-number">1.1.</span> <span class="nav-text">ISTA</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#lista"><span class="nav-number">1.2.</span> <span class="nav-text">LISTA</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%89%8D%E5%90%91%E4%BC%A0%E6%92%AD"><span class="nav-number">1.2.1.</span> <span class="nav-text">前向传播</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD"><span class="nav-number">1.3.</span> <span class="nav-text">反向传播</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BB%A3%E7%A0%81%E7%BC%96%E5%86%99"><span class="nav-number">1.4.</span> <span class="nav-text">代码编写</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#ista-1"><span class="nav-number">1.4.1.</span> <span class="nav-text">ISTA</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#lista-1"><span class="nav-number">1.4.2.</span> <span class="nav-text">LISTA</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%80%BB%E7%BB%93"><span class="nav-number">1.5.</span> <span class="nav-text">总结</span></a></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Staskaer"
      src="/imgs/theme_pic/head_img.png">
  <p class="site-author-name" itemprop="name">Staskaer</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">97</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">10</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">24</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/Staskaer" title="Github → https:&#x2F;&#x2F;github.com&#x2F;Staskaer" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i></a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:liujiaxin011121@gmail.com" title="E-Mail → mailto:liujiaxin011121@gmail.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i></a>
      </span>
      <span class="links-of-author-item">
        <a href="https://www.zhihu.com/people/staskaer" title="Zhihu → https:&#x2F;&#x2F;www.zhihu.com&#x2F;people&#x2F;staskaer" rel="noopener" target="_blank"><i class="fab fa-zhihu fa-fw"></i></a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2025</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Staskaer</span>
</div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  


<script>
NexT.utils.loadComments(document.querySelector('#valine-comments'), () => {
  NexT.utils.getScript('https://cdn.jsdelivr.net/npm/valine@1.5.1/dist/Valine.min.js', () => {
    var GUEST = ['nick', 'mail', 'link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item => {
      return GUEST.includes(item);
    });
    new Valine({
      el         : '#valine-comments',
      verify     : false,
      notify     : false,
      appId      : 'xH8NDrh9u4SQrUpQOd0lICnX-MdYXbMMI',
      appKey     : 'jl3JjPS4jsosZG29Zv24Y7LE',
      placeholder: "Just go go",
      avatar     : 'mm',
      meta       : guest,
      pageSize   : '10' || 10,
      visitor    : false,
      lang       : 'zh-Hans' || 'zh-cn',
      path       : location.pathname,
      recordIP   : false,
      serverURLs : 'https://xh8ndrh9.api.lncldglobal.com'
    });
  }, window.Valine);
});
</script>

</body>
</html>

